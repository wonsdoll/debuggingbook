{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "1"
        ]
      },
      "source": [
        "# Repairing Code Automatically\n",
        "\n",
        "So far, we have discussed how to track failures and how to locate defects in code. Let us now discuss how to _repair_ defects \u2013\u00a0that is, to correct the code such that the failure no longer occurs. We will discuss how to _repair code automatically_ \u2013\u00a0by systematically searching through possible fixes and evolving the most promising candidates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "2"
        ]
      },
      "outputs": [],
      "source": [
        "from bookutils import YouTubeVideo\n",
        "YouTubeVideo(\"UJTf7cW0idI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "3"
        ]
      },
      "source": [
        "**Prerequisites**\n",
        "\n",
        "* Re-read the [introduction to debugging](Intro_Debugging.ipynb), notably on how to properly fix code.\n",
        "* We make use of automatic fault localization, as discussed in the [chapter on statistical debugging](StatisticalDebugger.ipynb).\n",
        "* We make extensive use of code transformations, as discussed in the [chapter on tracing executions](Tracer.ipynb).\n",
        "* We make use of [delta debugging](DeltaDebugger.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "slideshow": {
          "slide_type": "skip"
        },
        "tags": [
          "4"
        ]
      },
      "outputs": [],
      "source": [
        "import bookutils.setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "tags": [
          "5"
        ]
      },
      "source": [
        "## Synopsis\n",
        "<!-- Automatically generated. Do not edit. -->\n",
        "\n",
        "To [use the code provided in this chapter](Importing.ipynb), write\n",
        "\n",
        "```python\n",
        ">>> from debuggingbook.Repairer import <identifier>\n",
        "```\n",
        "\n",
        "and then make use of the following features.\n",
        "\n",
        "\n",
        "This chapter provides tools and techniques for automated repair of program code. The `Repairer()` class takes a `RankingDebugger` debugger as input (such as `OchiaiDebugger` from [the chapter on statistical debugging](StatisticalDebugger.ipynb)). A typical setup looks like this:\n",
        "\n",
        "```python\n",
        "from debuggingbook.StatisticalDebugger import OchiaiDebugger\n",
        "\n",
        "debugger = OchiaiDebugger()\n",
        "for inputs in TESTCASES:\n",
        "    with debugger:\n",
        "        test_foo(inputs)\n",
        "...\n",
        "\n",
        "repairer = Repairer(debugger)\n",
        "```\n",
        "Here, `test_foo()` is a function that raises an exception if the tested function `foo()` fails. If `foo()` passes, `test_foo()` should not raise an exception.\n",
        "\n",
        "The `repair()` method of a `Repairer` searches for a repair of the code covered in the debugger (except for methods starting or ending in `test`, such that `foo()`, not `test_foo()` is repaired). `repair()` returns the best fix candidate as a pair `(tree, fitness)` where `tree` is a [Python abstract syntax tree](http://docs.python.org/3/library/ast) (AST) of the fix candidate, and `fitness` is the fitness of the candidate (a value between 0 and 1). A `fitness` of 1.0 means that the candidate passed all tests. A typical usage looks like this:\n",
        "\n",
        "```python\n",
        "tree, fitness = repairer.repair()\n",
        "print(ast.unparse(tree), fitness)\n",
        "```\n",
        "\n",
        "Here is a complete example for the `middle()` program. This is the original source code of `middle()`:\n",
        "\n",
        "```python\n",
        "def middle(x, y, z):  # type: ignore\n",
        "    if y < z:\n",
        "        if x < y:\n",
        "            return y\n",
        "        elif x < z:\n",
        "            return y\n",
        "    else:\n",
        "        if x > y:\n",
        "            return y\n",
        "        elif x > z:\n",
        "            return x\n",
        "    return z\n",
        "```\n",
        "We set up a function `middle_test()` that tests it. The `middle_debugger`  collects test cases and outcomes:\n",
        "\n",
        "```python\n",
        ">>> middle_debugger = OchiaiDebugger()\n",
        ">>> for x, y, z in MIDDLE_PASSING_TESTCASES + MIDDLE_FAILING_TESTCASES:\n",
        ">>>     with middle_debugger:\n",
        ">>>         middle_test(x, y, z)\n",
        "```\n",
        "The repairer attempts to repair the invoked function (`middle()`). The returned AST `tree` can be output via `ast.unparse()`:\n",
        "\n",
        "```python\n",
        ">>> middle_repairer = Repairer(middle_debugger)\n",
        ">>> tree, fitness = middle_repairer.repair()\n",
        ">>> print(ast.unparse(tree), fitness)\n",
        "def middle(x, y, z):\n",
        "    if y < z:\n",
        "        if x < z:\n",
        "            if x < y:\n",
        "                return y\n",
        "            else:\n",
        "                return x\n",
        "    elif x > y:\n",
        "        return y\n",
        "    elif x > z:\n",
        "        return x\n",
        "    return z\n",
        " 1.0\n",
        "\n",
        "```\n",
        "Here are the classes defined in this chapter. A `Repairer` repairs a program, using a `StatementMutator` and a `CrossoverOperator` to evolve a population of candidates.\n",
        "\n",
        "![](PICS/Repairer-synopsis-1.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": true,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "6"
        ]
      },
      "source": [
        "## Automatic Code Repairs\n",
        "\n",
        "So far, we have discussed how to locate defects in code, how to track failures back to the defects that caused them, and how to systematically determine failure conditions. Let us now address the last step in debugging \u2013\u00a0namely, how to _automatically fix code_.\n",
        "\n",
        "Already in the [introduction to debugging](Intro_Debugging.ipynb), we have discussed how to fix code manually. Notably, we have established that a _diagnosis_ (which induces a fix) should show _causality_ (i.e., how the defect causes the failure) and _incorrectness_ (how the defect is wrong). Is it possible to obtain such a diagnosis automatically?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "7"
        ]
      },
      "source": [
        "In this chapter, we introduce a technique of _automatic code repair_ \u2013\u00a0that is, for a given failure, automatically determine a fix that makes the failure go away. To do so, we randomly (but systematically) _mutate_ the program code \u2013\u00a0that is, insert, change, and delete fragments \u2013 until we find a change that actually causes the failing test to pass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "8"
        ]
      },
      "source": [
        "If this sounds like an audacious idea, that is because it is. But not only is _automated program repair_ one of the hottest topics of software research in the last decade, it is also being increasingly deployed in industry. At Facebook, for instance, every failing test report comes with an automatically generated _repair suggestion_ \u2013\u00a0a suggestion that already has been validated to work. Programmers can apply the suggestion as is or use it as basis for their own fixes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "9"
        ]
      },
      "source": [
        "### The middle() Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "10"
        ]
      },
      "source": [
        "Let us introduce our ongoing example. In the [chapter on statistical debugging](StatisticalDebugger.ipynb), we have introduced the `middle()` function \u2013\u00a0a function that returns the \"middle\" of three numbers `x`, `y`, and `z`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "11"
        ]
      },
      "outputs": [],
      "source": [
        "from StatisticalDebugger import middle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "12"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "from bookutils import print_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "13"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "import inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "14"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "_, first_lineno = inspect.getsourcelines(middle)\n",
        "middle_source = inspect.getsource(middle)\n",
        "print_content(middle_source, '.py', start_line_number=first_lineno)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "15"
        ]
      },
      "source": [
        "In most cases, `middle()` just runs fine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "16"
        ]
      },
      "outputs": [],
      "source": [
        "middle(4, 5, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "17"
        ]
      },
      "source": [
        "In some other cases, though, it does not work correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "18"
        ]
      },
      "outputs": [],
      "source": [
        "middle(2, 1, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "19"
        ]
      },
      "source": [
        "### Validated Repairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "20"
        ]
      },
      "source": [
        "Now, if we only want a repair that fixes this one given failure, this would be very easy. All we have to do is to replace the entire body by a single statement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "21"
        ]
      },
      "outputs": [],
      "source": [
        "def middle_sort_of_fixed(x, y, z):  # type: ignore\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "22"
        ]
      },
      "source": [
        "You will concur that the failure no longer occurs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "23"
        ]
      },
      "outputs": [],
      "source": [
        "middle_sort_of_fixed(2, 1, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "24"
        ]
      },
      "source": [
        "But this, of course, is not the aim of automatic fixes, nor of fixes in general: We want our fixes not only to make the given failure go away, but we also want the resulting code to be _correct_ (which, of course, is a lot harder)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "25"
        ]
      },
      "source": [
        "Automatic repair techniques therefore assume the existence of a _test suite_ that can check whether an implementation satisfies its requirements. Better yet, one can use the test suite to gradually check _how close_ one is to perfection: A piece of code that satisfies 99% of all tests is better than one that satisfies ~33% of all tests, as `middle_sort_of_fixed()` would do (assuming the test suite evenly checks the input space)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "26"
        ]
      },
      "source": [
        "### Genetic Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "27"
        ]
      },
      "source": [
        "The common approach for automatic repair follows the principle of _genetic optimization_. Roughly spoken, genetic optimization is a _metaheuristic_ inspired by the process of _natural selection_. The idea is to _evolve_ a selection of _candidate solutions_ towards a maximum _fitness_:\n",
        "\n",
        "1. Have a selection of _candidates_.\n",
        "2. Determine the _fitness_ of each candidate.\n",
        "3. Retain those candidates with the _highest fitness_.\n",
        "4. Create new candidates from the retained candidates, by applying genetic operations:\n",
        "    * _Mutation_ mutates some aspect of a candidate.\n",
        "    * _CrossoverOperator_ creates new candidates combining features of two candidates.\n",
        "5. Repeat until an optimal solution is found."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "28"
        ]
      },
      "source": [
        "Applied for automated program repair, this means the following steps:\n",
        "\n",
        "1. Have a _test suite_ with both failing and passing tests that helps to assert correctness of possible solutions.\n",
        "2. With the test suite, use [fault localization](StatisticalDebugger.ipynb) to determine potential code locations to be fixed.\n",
        "3. Systematically _mutate_ the code (by adding, changing, or deleting code) and _cross_ code to create possible fix candidates.\n",
        "4. Identify the _fittest_ fix candidates \u2013 that is, those that satisfy the most tests.\n",
        "5. _Evolve_ the fittest candidates until a perfect fix is found, or until time resources are depleted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "29"
        ]
      },
      "source": [
        "Let us illustrate these steps in the following sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "30"
        ]
      },
      "source": [
        "## A Test Suite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "31"
        ]
      },
      "source": [
        "In automated repair, the larger and the more thorough the test suite, the higher the quality of the resulting fix (if any). Hence, if we want to repair `middle()` automatically, we need a good test suite \u2013 with good inputs, but also with good checks. Note that running the test suite commonly takes the most time of automated repair, so a large test suite also comes with extra cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "32"
        ]
      },
      "source": [
        "Let us first focus on achieving high-quality repairs. Hence, we will use the extensive test suites introduced in the [chapter on statistical debugging](StatisticalDebugger.ipynb):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "33"
        ]
      },
      "outputs": [],
      "source": [
        "from StatisticalDebugger import MIDDLE_PASSING_TESTCASES, MIDDLE_FAILING_TESTCASES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "34"
        ]
      },
      "source": [
        "The `middle_test()` function fails whenever `middle()` returns an incorrect result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "35"
        ]
      },
      "outputs": [],
      "source": [
        "def middle_test(x: int, y: int, z: int) -> None:\n",
        "    m = middle(x, y, z)\n",
        "    assert m == sorted([x, y, z])[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "36"
        ]
      },
      "outputs": [],
      "source": [
        "from ExpectError import ExpectError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "37"
        ]
      },
      "outputs": [],
      "source": [
        "with ExpectError():\n",
        "    middle_test(2, 1, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "38"
        ]
      },
      "source": [
        "## Locating the Defect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "39"
        ]
      },
      "source": [
        "Our next step is to find potential defect locations \u2013\u00a0that is, those locations in the code our mutations should focus upon. Since we already do have two test suites, we can make use of [statistical debugging](StatisticalDebugger.ipynb) to identify likely faulty locations.  Our `OchiaiDebugger` ranks individual code lines by how frequently they are executed in failing runs (and not in passing runs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "40"
        ]
      },
      "outputs": [],
      "source": [
        "from StatisticalDebugger import OchiaiDebugger, RankingDebugger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "41"
        ]
      },
      "outputs": [],
      "source": [
        "middle_debugger = OchiaiDebugger()\n",
        "\n",
        "for x, y, z in MIDDLE_PASSING_TESTCASES + MIDDLE_FAILING_TESTCASES:\n",
        "    with middle_debugger:\n",
        "        middle_test(x, y, z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "42"
        ]
      },
      "source": [
        "We see that the upper half of the `middle()` code is definitely more suspicious:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "43"
        ]
      },
      "outputs": [],
      "source": [
        "middle_debugger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "44"
        ]
      },
      "source": [
        "The most suspicious line is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "45"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "location = middle_debugger.rank()[0]\n",
        "(func_name, lineno) = location\n",
        "lines, first_lineno = inspect.getsourcelines(middle)\n",
        "print(lineno, end=\"\")\n",
        "print_content(lines[lineno - first_lineno], '.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "46"
        ]
      },
      "source": [
        "with a suspiciousness of:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "47"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "middle_debugger.suspiciousness(location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "48"
        ]
      },
      "source": [
        "## Random Code Mutations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "49"
        ]
      },
      "source": [
        "Our third step in automatic code repair is to _randomly mutate the code_. Specifically, we want to randomly _delete_, _insert_, and _replace_ statements in the program to be repaired. However, simply synthesizing code _from scratch_ is unlikely to yield anything meaningful \u2013 the number of combinations is simply far too high. Already for a three-character identifier name, we have more than 200,000 combinations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "50"
        ]
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "51"
        ]
      },
      "outputs": [],
      "source": [
        "string.ascii_letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "52"
        ]
      },
      "outputs": [],
      "source": [
        "len(string.ascii_letters + '_') * \\\n",
        "  len(string.ascii_letters + '_' + string.digits) * \\\n",
        "  len(string.ascii_letters + '_' + string.digits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "53"
        ]
      },
      "source": [
        "Hence, we do _not_ synthesize code from scratch, but instead _reuse_ elements from the program to be fixed, hypothesizing that \"a program that contains an error in one area likely implements the correct behavior elsewhere\" \\cite{LeGoues2012}. This insight has been dubbed the *plastic surgery hypothesis*: content of new code can often be assembled out of fragments of code that already exist in the code base \\citeBarr2014}."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "54"
        ]
      },
      "source": [
        "For our \"plastic surgery\", we do not operate on a _textual_ representation of the program, but rather on a _structural_ representation, which by construction allows us to avoid lexical and syntactical errors in the first place.\n",
        "\n",
        "This structural representation is the _abstract syntax tree_ (AST), which we already have seen in various chapters, such as the [chapter on delta debugging](DeltaDebugger.ipynb), the [chapter on tracing](Tracer.ipynb), and excessively in the [chapter on slicing](Slicer.ipynb). The [official Python `ast` reference](http://docs.python.org/3/library/ast) is complete, but a bit brief; the documentation [\"Green Tree Snakes - the missing Python AST docs\"](https://greentreesnakes.readthedocs.io/en/latest/) provides an excellent introduction.\n",
        "\n",
        "Recapitulating, an AST is a tree representation of the program, showing a hierarchical structure of the program's elements. Here is the AST for our `middle()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "55"
        ]
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "56"
        ]
      },
      "outputs": [],
      "source": [
        "from bookutils import print_content, show_ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "57"
        ]
      },
      "outputs": [],
      "source": [
        "def middle_tree() -> ast.AST:\n",
        "    return ast.parse(inspect.getsource(middle))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "58"
        ]
      },
      "outputs": [],
      "source": [
        "show_ast(middle_tree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "59"
        ]
      },
      "source": [
        " You see that it consists of one function definition (`FunctionDef`) with three `arguments` and two statements \u2013\u00a0one `If` and one `Return`. Each `If` subtree has three branches \u2013\u00a0one for the condition (`test`), one for the body to be executed if the condition is true (`body`), and one for the `else` case (`orelse`). The `body` and `orelse` branches again are lists of statements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "60"
        ]
      },
      "source": [
        "An AST can also be shown as text, which is more compact, yet reveals more information. `ast.dump()` gives not only the class names of elements, but also how they are constructed \u2013\u00a0actually, the whole expression can be used to construct an AST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "61"
        ]
      },
      "outputs": [],
      "source": [
        "print(ast.dump(middle_tree()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "62"
        ]
      },
      "source": [
        "This is the path to the first `return` statement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "63"
        ]
      },
      "outputs": [],
      "source": [
        "ast.dump(middle_tree().body[0].body[0].body[0].body[0])  # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "64"
        ]
      },
      "source": [
        "### Picking Statements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "65"
        ]
      },
      "source": [
        "For our mutation operators, we want to use statements from the program itself. Hence, we need a means to find those very statements. The `StatementVisitor` class iterates through an AST, adding all statements it finds in function definitions to its `statements` list. To do so, it subclasses the Python `ast` `NodeVisitor` class, described in the [official Python `ast` reference](http://docs.python.org/3/library/ast)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "66"
        ]
      },
      "outputs": [],
      "source": [
        "from ast import NodeVisitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "67"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "from typing import Any, Callable, Optional, Type, Tuple\n",
        "from typing import Dict, Union, Set, List, cast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "68"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementVisitor(NodeVisitor):\n",
        "    \"\"\"Visit all statements within function defs in an AST\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.statements: List[Tuple[ast.AST, str]] = []\n",
        "        self.func_name = \"\"\n",
        "        self.statements_seen: Set[Tuple[ast.AST, str]] = set()\n",
        "        super().__init__()\n",
        "\n",
        "    def add_statements(self, node: ast.AST, attr: str) -> None:\n",
        "        elems: List[ast.AST] = getattr(node, attr, [])\n",
        "        if not isinstance(elems, list):\n",
        "            elems = [elems]  # type: ignore\n",
        "\n",
        "        for elem in elems:\n",
        "            stmt = (elem, self.func_name)\n",
        "            if stmt in self.statements_seen:\n",
        "                continue\n",
        "\n",
        "            self.statements.append(stmt)\n",
        "            self.statements_seen.add(stmt)\n",
        "\n",
        "    def visit_node(self, node: ast.AST) -> None:\n",
        "        # Any node other than the ones listed below\n",
        "        self.add_statements(node, 'body')\n",
        "        self.add_statements(node, 'orelse')\n",
        "\n",
        "    def visit_Module(self, node: ast.Module) -> None:\n",
        "        # Module children are defs, classes and globals - don't add\n",
        "        super().generic_visit(node)\n",
        "\n",
        "    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n",
        "        # Class children are defs and globals - don't add\n",
        "        super().generic_visit(node)\n",
        "\n",
        "    def generic_visit(self, node: ast.AST) -> None:\n",
        "        self.visit_node(node)\n",
        "        super().generic_visit(node)\n",
        "\n",
        "    def visit_FunctionDef(self,\n",
        "                          node: Union[ast.FunctionDef, ast.AsyncFunctionDef]) -> None:\n",
        "        if not self.func_name:\n",
        "            self.func_name = node.name\n",
        "\n",
        "        self.visit_node(node)\n",
        "        super().generic_visit(node)\n",
        "        self.func_name = \"\"\n",
        "\n",
        "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> None:\n",
        "        return self.visit_FunctionDef(node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "69"
        ]
      },
      "source": [
        "The function `all_statements()` returns all statements in the given AST `tree`. If an `ast` class `tp` is given, it only returns instances of that class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "70"
        ]
      },
      "outputs": [],
      "source": [
        "def all_statements_and_functions(tree: ast.AST, \n",
        "                                 tp: Optional[Type] = None) -> \\\n",
        "                                 List[Tuple[ast.AST, str]]:\n",
        "    \"\"\"\n",
        "    Return a list of pairs (`statement`, `function`) for all statements in `tree`.\n",
        "    If `tp` is given, return only statements of that class.\n",
        "    \"\"\"\n",
        "\n",
        "    visitor = StatementVisitor()\n",
        "    visitor.visit(tree)\n",
        "    statements = visitor.statements\n",
        "    if tp is not None:\n",
        "        statements = [s for s in statements if isinstance(s[0], tp)]\n",
        "\n",
        "    return statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "71"
        ]
      },
      "outputs": [],
      "source": [
        "def all_statements(tree: ast.AST, tp: Optional[Type] = None) -> List[ast.AST]:\n",
        "    \"\"\"\n",
        "    Return a list of all statements in `tree`.\n",
        "    If `tp` is given, return only statements of that class.\n",
        "    \"\"\"\n",
        "\n",
        "    return [stmt for stmt, func_name in all_statements_and_functions(tree, tp)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "72"
        ]
      },
      "source": [
        "Here are all the `return` statements in `middle()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "73"
        ]
      },
      "outputs": [],
      "source": [
        "all_statements(middle_tree(), ast.Return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "74"
        ]
      },
      "outputs": [],
      "source": [
        "all_statements_and_functions(middle_tree(), ast.If)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "75"
        ]
      },
      "source": [
        "We can randomly pick an element:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "76"
        ]
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "77"
        ]
      },
      "outputs": [],
      "source": [
        "random_node = random.choice(all_statements(middle_tree()))\n",
        "ast.unparse(random_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "78"
        ]
      },
      "source": [
        "### Mutating Statements\n",
        "\n",
        "The main part in mutation, however, is to actually mutate the code of the program under test. To this end, we introduce a `StatementMutator` class \u2013 a subclass of `NodeTransformer`, described in the [official Python `ast` reference](http://docs.python.org/3/library/ast)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "79"
        ]
      },
      "source": [
        "The constructor provides various keyword arguments to configure the mutator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "80"
        ]
      },
      "outputs": [],
      "source": [
        "from ast import NodeTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "81"
        ]
      },
      "outputs": [],
      "source": [
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "82"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(NodeTransformer):\n",
        "    \"\"\"Mutate statements in an AST for automated repair.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 suspiciousness_func:\n",
        "                     Optional[Callable[[Tuple[Callable, int]], float]] = None,\n",
        "                 source: Optional[List[ast.AST]] = None,\n",
        "                 log: Union[bool, int] = False) -> None:\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        `suspiciousness_func` is a function that takes a location\n",
        "        (function, line_number) and returns a suspiciousness value\n",
        "        between 0 and 1.0. If not given, all locations get the same \n",
        "        suspiciousness of 1.0.\n",
        "        `source` is a list of statements to choose from.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.log = log\n",
        "\n",
        "        if suspiciousness_func is None:\n",
        "            def suspiciousness_func(location: Tuple[Callable, int]) -> float:\n",
        "                return 1.0\n",
        "        assert suspiciousness_func is not None\n",
        "\n",
        "        self.suspiciousness_func: Callable = suspiciousness_func\n",
        "\n",
        "        if source is None:\n",
        "            source = []\n",
        "        self.source = source\n",
        "\n",
        "        if self.log > 1:\n",
        "            for i, node in enumerate(self.source):\n",
        "                print(f\"Source for repairs #{i}:\")\n",
        "                print_content(ast.unparse(node), '.py')\n",
        "                print()\n",
        "                print()\n",
        "\n",
        "        self.mutations = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "83"
        ]
      },
      "source": [
        "#### Choosing Suspicious Statements to Mutate\n",
        "\n",
        "We start with deciding which AST nodes to mutate. The method `node_suspiciousness()` returns the suspiciousness for a given node, by invoking the suspiciousness function `suspiciousness_func` given during initialization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "84"
        ]
      },
      "outputs": [],
      "source": [
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "85"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def node_suspiciousness(self, stmt: ast.AST, func_name: str) -> float:\n",
        "        if not hasattr(stmt, 'lineno'):\n",
        "            warnings.warn(f\"{self.format_node(stmt)}: Expected line number\")\n",
        "            return 0.0\n",
        "\n",
        "        suspiciousness = self.suspiciousness_func((func_name, stmt.lineno))\n",
        "        if suspiciousness is None:  # not executed\n",
        "            return 0.0\n",
        "\n",
        "        return suspiciousness\n",
        "\n",
        "    def format_node(self, node: ast.AST) -> str:  # type: ignore\n",
        "        ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "86"
        ]
      },
      "source": [
        "The method `node_to_be_mutated()` picks a node (statement) to be mutated. It determines the suspiciousness of all statements, and invokes `random.choices()`, using the suspiciousness as weight. Unsuspicious statements (with zero weight) will not be chosen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "87"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def node_to_be_mutated(self, tree: ast.AST) -> ast.AST:\n",
        "        statements = all_statements_and_functions(tree)\n",
        "        assert len(statements) > 0, \"No statements\"\n",
        "\n",
        "        weights = [self.node_suspiciousness(stmt, func_name) \n",
        "                   for stmt, func_name in statements]\n",
        "        stmts = [stmt for stmt, func_name in statements]\n",
        "\n",
        "        if self.log > 1:\n",
        "            print(\"Weights:\")\n",
        "            for i, stmt in enumerate(statements):\n",
        "                node, func_name = stmt\n",
        "                print(f\"{weights[i]:.2} {self.format_node(node)}\")\n",
        "\n",
        "        if sum(weights) == 0.0:\n",
        "            # No suspicious line\n",
        "            return random.choice(stmts)\n",
        "        else:\n",
        "            return random.choices(stmts, weights=weights)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "88"
        ]
      },
      "source": [
        "#### Choosing a Mutation Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "89"
        ]
      },
      "source": [
        "The method `visit()` is invoked on all nodes. For nodes marked with a `mutate_me` attribute, it randomly chooses a mutation method (`choose_op()`) and then invokes it on the node.\n",
        "\n",
        "According to the rules of `NodeTransformer`, the mutation method can return\n",
        "\n",
        "* a new node or a list of nodes, replacing the current node;\n",
        "* `None`, deleting it; or\n",
        "* the node itself, keeping things as they are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "90"
        ]
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "91"
        ]
      },
      "outputs": [],
      "source": [
        "RE_SPACE = re.compile(r'[ \\t\\n]+')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "92"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def choose_op(self) -> Callable:\n",
        "        return random.choice([self.insert, self.swap, self.delete])\n",
        "\n",
        "    def visit(self, node: ast.AST) -> ast.AST:\n",
        "        super().visit(node)  # Visits (and transforms?) children\n",
        "\n",
        "        if not node.mutate_me:  # type: ignore\n",
        "            return node\n",
        "\n",
        "        op = self.choose_op()\n",
        "        new_node = op(node)\n",
        "        self.mutations += 1\n",
        "\n",
        "        if self.log:\n",
        "            print(f\"{node.lineno:4}:{op.__name__ + ':':7} \"  # type: ignore\n",
        "                  f\"{self.format_node(node)} \"\n",
        "                  f\"becomes {self.format_node(new_node)}\")\n",
        "\n",
        "        return new_node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "93"
        ]
      },
      "source": [
        "#### Swapping Statements\n",
        "\n",
        "Our first mutator is `swap()`, which replaces the current node `NODE` by a random node found in `source` (using a newly defined `choose_statement()`).\n",
        "\n",
        "As a rule of thumb, we try to avoid inserting entire subtrees with all attached statements; and try to respect only the first line of a node. If the new node has the form \n",
        "\n",
        "```python\n",
        "if P:\n",
        "    BODY\n",
        "```\n",
        "\n",
        "we thus only insert \n",
        "\n",
        "```python\n",
        "if P: \n",
        "    pass\n",
        "```\n",
        "\n",
        "since the statements in `BODY` have a later chance to get inserted. The same holds for all constructs that have a `BODY`, i.e. `while`, `for`, `try`, `with`, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "94"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def choose_statement(self) -> ast.AST:\n",
        "        return copy.deepcopy(random.choice(self.source))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "95"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def swap(self, node: ast.AST) -> ast.AST:\n",
        "        \"\"\"Replace `node` with a random node from `source`\"\"\"\n",
        "        new_node = self.choose_statement()\n",
        "\n",
        "        if isinstance(new_node, ast.stmt):\n",
        "            # The source `if P: X` is added as `if P: pass`\n",
        "            if hasattr(new_node, 'body'):\n",
        "                new_node.body = [ast.Pass()]  # type: ignore\n",
        "            if hasattr(new_node, 'orelse'):\n",
        "                new_node.orelse = []  # type: ignore\n",
        "            if hasattr(new_node, 'finalbody'):\n",
        "                new_node.finalbody = []  # type: ignore\n",
        "\n",
        "        # ast.copy_location(new_node, node)\n",
        "        return new_node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "96"
        ]
      },
      "source": [
        "#### Inserting Statements\n",
        "\n",
        "Our next mutator is `insert()`, which randomly chooses some node from `source` and inserts it after the current node `NODE`. (If `NODE` is a `return` statement, then we insert the new node _before_ `NODE`.)\n",
        "\n",
        "If the statement to be inserted has the form\n",
        "\n",
        "```python\n",
        "if P:\n",
        "    BODY\n",
        "```\n",
        "\n",
        "we only insert the \"header\" of the `if`, resulting in\n",
        "\n",
        "```python\n",
        "if P: \n",
        "    NODE\n",
        "```\n",
        "\n",
        "Again, this applies to all constructs that have a `BODY`, i.e., `while`, `for`, `try`, `with`, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "97"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def insert(self, node: ast.AST) -> Union[ast.AST, List[ast.AST]]:\n",
        "        \"\"\"Insert a random node from `source` after `node`\"\"\"\n",
        "        new_node = self.choose_statement()\n",
        "\n",
        "        if isinstance(new_node, ast.stmt) and hasattr(new_node, 'body'):\n",
        "            # Inserting `if P: X` as `if P:`\n",
        "            new_node.body = [node]  # type: ignore\n",
        "            if hasattr(new_node, 'orelse'):\n",
        "                new_node.orelse = []  # type: ignore\n",
        "            if hasattr(new_node, 'finalbody'):\n",
        "                new_node.finalbody = []  # type: ignore\n",
        "            # ast.copy_location(new_node, node)\n",
        "            return new_node\n",
        "\n",
        "        # Only insert before `return`, not after it\n",
        "        if isinstance(node, ast.Return):\n",
        "            if isinstance(new_node, ast.Return):\n",
        "                return new_node\n",
        "            else:\n",
        "                return [new_node, node]\n",
        "\n",
        "        return [node, new_node]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "98"
        ]
      },
      "source": [
        "#### Deleting Statements\n",
        "\n",
        "Our last mutator is `delete()`, which deletes the current node `NODE`. The standard case is to replace `NODE` by a `pass` statement.\n",
        "\n",
        "If the statement to be deleted has the form\n",
        "\n",
        "```python\n",
        "if P:\n",
        "    BODY\n",
        "```\n",
        "\n",
        "we only delete the \"header\" of the `if`, resulting in\n",
        "\n",
        "```python\n",
        "BODY\n",
        "```\n",
        "\n",
        "Again, this applies to all constructs that have a `BODY`, i.e., `while`, `for`, `try`, `with`, and more. If the statement to be deleted has multiple branches, a random branch is chosen (e.g., the `else` branch of an `if` statement)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "99"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def delete(self, node: ast.AST) -> None:\n",
        "        \"\"\"Delete `node`.\"\"\"\n",
        "\n",
        "        branches = [attr for attr in ['body', 'orelse', 'finalbody']\n",
        "                    if hasattr(node, attr) and getattr(node, attr)]\n",
        "        if branches:\n",
        "            # Replace `if P: S` by `S`\n",
        "            branch = random.choice(branches)\n",
        "            new_node = getattr(node, branch)\n",
        "            return new_node\n",
        "\n",
        "        if isinstance(node, ast.stmt):\n",
        "            # Avoid empty bodies; make this a `pass` statement\n",
        "            new_node = ast.Pass()\n",
        "            ast.copy_location(new_node, node)\n",
        "            return new_node\n",
        "\n",
        "        return None  # Just delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "100"
        ]
      },
      "outputs": [],
      "source": [
        "from bookutils import quiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "101"
        ]
      },
      "outputs": [],
      "source": [
        "quiz(\"Why are statements replaced by `pass` rather than deleted?\",\n",
        "     [\n",
        "         \"Because `if P: pass` is valid Python, while `if P:` is not\",\n",
        "         \"Because in Python, bodies for `if`, `while`, etc. cannot be empty\",\n",
        "         \"Because a `pass` node makes a target for future mutations\",\n",
        "         \"Because it causes the tests to pass\"\n",
        "     ], '[3 ^ n for n in range(3)]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "102"
        ]
      },
      "source": [
        "Indeed, Python's `compile()` will fail if any of the bodies is an empty list. Also, it leaves us a statement that can be evolved further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "103"
        ]
      },
      "source": [
        "#### Helpers\n",
        "\n",
        "For logging purposes, we introduce a helper function `format_node()` that returns a short string representation of the node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "104"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    NODE_MAX_LENGTH = 20\n",
        "\n",
        "    def format_node(self, node: ast.AST) -> str:\n",
        "        \"\"\"Return a string representation for `node`.\"\"\"\n",
        "        if node is None:\n",
        "            return \"None\"\n",
        "\n",
        "        if isinstance(node, list):\n",
        "            return \"; \".join(self.format_node(elem) for elem in node)\n",
        "\n",
        "        s = RE_SPACE.sub(' ', ast.unparse(node)).strip()\n",
        "        if len(s) > self.NODE_MAX_LENGTH - len(\"...\"):\n",
        "            s = s[:self.NODE_MAX_LENGTH] + \"...\"\n",
        "        return repr(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "105"
        ]
      },
      "source": [
        "#### All Together\n",
        "\n",
        "Let us now create the main entry point, which is `mutate()`. It picks the node to be mutated and marks it with a `mutate_me` attribute. By calling `visit()`, it then sets off the `NodeTransformer` transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "106"
        ]
      },
      "outputs": [],
      "source": [
        "class StatementMutator(StatementMutator):\n",
        "    def mutate(self, tree: ast.AST) -> ast.AST:\n",
        "        \"\"\"Mutate the given AST `tree` in place. Return mutated tree.\"\"\"\n",
        "\n",
        "        assert isinstance(tree, ast.AST)\n",
        "\n",
        "        tree = copy.deepcopy(tree)\n",
        "\n",
        "        if not self.source:\n",
        "            self.source = all_statements(tree)\n",
        "\n",
        "        for node in ast.walk(tree):\n",
        "            node.mutate_me = False  # type: ignore\n",
        "\n",
        "        node = self.node_to_be_mutated(tree)\n",
        "        node.mutate_me = True  # type: ignore\n",
        "\n",
        "        self.mutations = 0\n",
        "\n",
        "        tree = self.visit(tree)\n",
        "\n",
        "        if self.mutations == 0:\n",
        "            warnings.warn(\"No mutations found\")\n",
        "\n",
        "        ast.fix_missing_locations(tree)\n",
        "        return tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "107"
        ]
      },
      "source": [
        "Here are a number of transformations applied by `StatementMutator`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "108"
        ]
      },
      "outputs": [],
      "source": [
        "mutator = StatementMutator(log=True)\n",
        "for i in range(10):\n",
        "    new_tree = mutator.mutate(middle_tree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "109"
        ]
      },
      "source": [
        "This is the effect of the last mutator applied on `middle`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "110"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(new_tree), '.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "111"
        ]
      },
      "source": [
        "## Fitness\n",
        "\n",
        "Now that we can apply random mutations to code, let us find out how good these mutations are. Given our test suites for `middle`, we can check for a given code candidate how many of the previously passing test cases it passes, and how many of the failing test cases it passes. The more tests pass, the higher the _fitness_ of the candidate."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "112"
        ]
      },
      "source": [
        "Not all passing tests have the same value, though. We want to prevent _regressions_ \u2013\u00a0that is, having a fix that breaks a previously passing test. The values of `WEIGHT_PASSING` and `WEIGHT_FAILING` set the relative weight (or importance) of passing vs. failing tests; we see that keeping passing tests passing is far more important than fixing failing tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "113"
        ]
      },
      "outputs": [],
      "source": [
        "WEIGHT_PASSING = 0.99\n",
        "WEIGHT_FAILING = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "114"
        ]
      },
      "outputs": [],
      "source": [
        "def middle_fitness(tree: ast.AST) -> float:\n",
        "    \"\"\"Compute fitness of a `middle()` candidate given in `tree`\"\"\"\n",
        "    original_middle = middle\n",
        "\n",
        "    try:\n",
        "        code = compile(cast(ast.Module, tree), '<fitness>', 'exec')\n",
        "    except ValueError:\n",
        "        return 0  # Compilation error\n",
        "\n",
        "    exec(code, globals())\n",
        "\n",
        "    passing_passed = 0\n",
        "    failing_passed = 0\n",
        "\n",
        "    # Test how many of the passing runs pass\n",
        "    for x, y, z in MIDDLE_PASSING_TESTCASES:\n",
        "        try:\n",
        "            middle_test(x, y, z)\n",
        "            passing_passed += 1\n",
        "        except AssertionError:\n",
        "            pass\n",
        "\n",
        "    passing_ratio = passing_passed / len(MIDDLE_PASSING_TESTCASES)\n",
        "\n",
        "    # Test how many of the failing runs pass\n",
        "    for x, y, z in MIDDLE_FAILING_TESTCASES:\n",
        "        try:\n",
        "            middle_test(x, y, z)\n",
        "            failing_passed += 1\n",
        "        except AssertionError:\n",
        "            pass\n",
        "\n",
        "    failing_ratio = failing_passed / len(MIDDLE_FAILING_TESTCASES)\n",
        "\n",
        "    fitness = (WEIGHT_PASSING * passing_ratio +\n",
        "               WEIGHT_FAILING * failing_ratio)\n",
        "\n",
        "    globals()['middle'] = original_middle\n",
        "    return fitness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "115"
        ]
      },
      "source": [
        "Our faulty `middle()` program has a fitness of `WEIGHT_PASSING` (99%), because it passes all the passing tests (but none of the failing ones)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "116"
        ]
      },
      "outputs": [],
      "source": [
        "middle_fitness(middle_tree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "117"
        ]
      },
      "source": [
        "Our \"sort of fixed\" version of `middle()` gets a much lower fitness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "118"
        ]
      },
      "outputs": [],
      "source": [
        "middle_fitness(ast.parse(\"def middle(x, y, z): return x\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "119"
        ]
      },
      "source": [
        "In the [chapter on statistical debugging](StatisticalDebugger), we also defined a fixed version of `middle()`. This gets a fitness of 1.0, passing all tests. (We won't use this fixed version for automated repairs.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "120"
        ]
      },
      "outputs": [],
      "source": [
        "from StatisticalDebugger import middle_fixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "121"
        ]
      },
      "outputs": [],
      "source": [
        "middle_fixed_source = \\\n",
        "    inspect.getsource(middle_fixed).replace('middle_fixed', 'middle').strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "122"
        ]
      },
      "outputs": [],
      "source": [
        "middle_fitness(ast.parse(middle_fixed_source))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "123"
        ]
      },
      "source": [
        "## Population\n",
        "\n",
        "We now set up a _population_ of fix candidates to evolve over time.  A higher population size will yield more candidates to check, but also need more time to test; a lower population size will yield fewer candidates, but allow for more evolution steps.  We choose a population size of 40 (from \\cite{LeGoues2012})."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "124"
        ]
      },
      "outputs": [],
      "source": [
        "POPULATION_SIZE = 40\n",
        "middle_mutator = StatementMutator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "125"
        ]
      },
      "outputs": [],
      "source": [
        "MIDDLE_POPULATION = [middle_tree()] + \\\n",
        "    [middle_mutator.mutate(middle_tree()) for i in range(POPULATION_SIZE - 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "126"
        ]
      },
      "source": [
        "We sort the fix candidates according to their fitness. This actually runs all tests on all candidates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "127"
        ]
      },
      "outputs": [],
      "source": [
        "MIDDLE_POPULATION.sort(key=middle_fitness, reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "128"
        ]
      },
      "source": [
        "The candidate with the highest fitness is still our original (faulty) `middle()` code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "129"
        ]
      },
      "outputs": [],
      "source": [
        "print(ast.unparse(MIDDLE_POPULATION[0]),\n",
        "      middle_fitness(MIDDLE_POPULATION[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "130"
        ]
      },
      "source": [
        "At the other end of the spectrum, the candidate with the lowest fitness has some vital functionality removed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "131"
        ]
      },
      "outputs": [],
      "source": [
        "print(ast.unparse(MIDDLE_POPULATION[-1]),\n",
        "      middle_fitness(MIDDLE_POPULATION[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "132"
        ]
      },
      "source": [
        "## Evolution\n",
        "\n",
        "To evolve our population of candidates, we fill up the population with mutations created from the population, using a `StatementMutator` as described above to create these mutations. Then we reduce the population to its original size, keeping the fittest candidates.\n",
        "<!-- TODO: shouldn't there be some kind of randomness to also keep sometimes candidates with lesser fitness? -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "133"
        ]
      },
      "outputs": [],
      "source": [
        "def evolve_middle() -> None:\n",
        "    global MIDDLE_POPULATION\n",
        "\n",
        "    source = all_statements(middle_tree())\n",
        "    mutator = StatementMutator(source=source)\n",
        "\n",
        "    n = len(MIDDLE_POPULATION)\n",
        "\n",
        "    offspring: List[ast.AST] = []\n",
        "    while len(offspring) < n:\n",
        "        parent = random.choice(MIDDLE_POPULATION)\n",
        "        offspring.append(mutator.mutate(parent))\n",
        "\n",
        "    MIDDLE_POPULATION += offspring\n",
        "    MIDDLE_POPULATION.sort(key=middle_fitness, reverse=True)\n",
        "    MIDDLE_POPULATION = MIDDLE_POPULATION[:n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "134"
        ]
      },
      "source": [
        "This is what happens when evolving our population for the first time; the original source is still our best candidate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "135"
        ]
      },
      "outputs": [],
      "source": [
        "evolve_middle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "136"
        ]
      },
      "outputs": [],
      "source": [
        "tree = MIDDLE_POPULATION[0]\n",
        "print(ast.unparse(tree), middle_fitness(tree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "137"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert middle_fitness(tree) < 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "138"
        ]
      },
      "source": [
        "However, nothing keeps us from evolving for a few generations more..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "139"
        ]
      },
      "outputs": [],
      "source": [
        "for i in range(50):\n",
        "    evolve_middle()\n",
        "    best_middle_tree = MIDDLE_POPULATION[0]\n",
        "    fitness = middle_fitness(best_middle_tree)\n",
        "    print(f\"\\rIteration {i:2}: fitness = {fitness}  \", end=\"\")\n",
        "    if fitness >= 1.0:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "140"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert middle_fitness(best_middle_tree) >= 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "141"
        ]
      },
      "source": [
        "Success! We find a candidate that actually passes all tests, including the failing ones. Here is the candidate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "142"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(best_middle_tree), '.py', start_line_number=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "143"
        ]
      },
      "source": [
        "... and yes, it passes all tests:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "144"
        ]
      },
      "outputs": [],
      "source": [
        "original_middle = middle\n",
        "code = compile(cast(ast.Module, best_middle_tree), '<string>', 'exec')\n",
        "exec(code, globals())\n",
        "\n",
        "for x, y, z in MIDDLE_PASSING_TESTCASES + MIDDLE_FAILING_TESTCASES:\n",
        "    middle_test(x, y, z)\n",
        "\n",
        "middle = original_middle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "145"
        ]
      },
      "source": [
        "As the code is already validated by hundreds of test cases, it is very valuable for the programmer. Even if the programmer decides not to use the code as is, the location gives very strong hints on which code to examine and where to apply a fix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "146"
        ]
      },
      "source": [
        "However, a closer look at our fix candidate shows that there is some amount of redundancy \u2013 that is, superfluous statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "147"
        ]
      },
      "outputs": [],
      "source": [
        "quiz(\"Some of the lines in our fix candidate are redundant. \"\n",
        "     \"Which are these?\",\n",
        "    [\n",
        "        \"Line 3: `if x < y:`\",\n",
        "        \"Line 4: `if x < z:`\",\n",
        "        \"Line 5: `return y`\",\n",
        "        \"Line 13: `return z`\"\n",
        "    ], '[eval(chr(100 - x)) for x in [48, 50]]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "148"
        ]
      },
      "source": [
        "## Simplifying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "149"
        ]
      },
      "source": [
        "As demonstrated in the chapter on [reducing failure-inducing inputs](DeltaDebugger.ipynb), we can use delta debugging on code to get rid of these superfluous statements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "150"
        ]
      },
      "source": [
        "The trick for simplification is to have the test function (`test_middle_lines()`) declare a fitness of 1.0 as a \"failure\". Delta debugging will then simplify the input as long as the \"failure\" (and hence the maximum fitness obtained) persists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "151"
        ]
      },
      "outputs": [],
      "source": [
        "from DeltaDebugger import DeltaDebugger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "152"
        ]
      },
      "outputs": [],
      "source": [
        "middle_lines = ast.unparse(best_middle_tree).strip().split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "153"
        ]
      },
      "outputs": [],
      "source": [
        "def test_middle_lines(lines: List[str]) -> None:\n",
        "    source = \"\\n\".join(lines)\n",
        "    tree = ast.parse(source)\n",
        "    assert middle_fitness(tree) < 1.0  # \"Fail\" only while fitness is 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "154"
        ]
      },
      "outputs": [],
      "source": [
        "with DeltaDebugger() as dd:\n",
        "    test_middle_lines(middle_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "155"
        ]
      },
      "outputs": [],
      "source": [
        "reduced_lines = dd.min_args()['lines']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "156"
        ]
      },
      "outputs": [],
      "source": [
        "reduced_source = \"\\n\".join(reduced_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "157"
        ]
      },
      "outputs": [],
      "source": [
        "repaired_source = ast.unparse(ast.parse(reduced_source))  # normalize\n",
        "print_content(repaired_source, '.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "158"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert len(reduced_lines) < len(middle_lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "159"
        ]
      },
      "source": [
        "Success! Delta Debugging has eliminated the superfluous statements. We can present the difference to the original as a patch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "160"
        ]
      },
      "outputs": [],
      "source": [
        "original_source = ast.unparse(ast.parse(middle_source))  # normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "161"
        ]
      },
      "outputs": [],
      "source": [
        "from ChangeDebugger import diff, print_patch  # minor dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "162"
        ]
      },
      "outputs": [],
      "source": [
        "for patch in diff(original_source, repaired_source):\n",
        "    print_patch(patch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "163"
        ]
      },
      "source": [
        "We can present this patch to the programmer, who will then immediately know what to fix in the `middle()` code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "164"
        ]
      },
      "source": [
        "## Crossover\n",
        "\n",
        "So far, we have only applied one kind of genetic operators \u2013 mutation. There is a second one, though, also inspired by natural selection. \n",
        "\n",
        "The *crossover* operation mutates two strands of genes, as illustrated in the following picture. We have two parents (red and blue), each as a sequence of genes. To create \"crossed\" children, we pick a _crossover point_ and exchange the strands at this very point:\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/OnePointCrossover.svg/500px-OnePointCrossover.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "165"
        ]
      },
      "source": [
        "We implement a `CrossoverOperator` class that implements such an operation on two randomly chosen statement lists of two programs. It is used as\n",
        "\n",
        "```python\n",
        "crossover = CrossoverOperator()\n",
        "crossover.crossover(tree_p1, tree_p2)\n",
        "```\n",
        "\n",
        "where `tree_p1` and `tree_p2` are two ASTs that are changed in place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "166"
        ]
      },
      "source": [
        "### Excursion: Implementing Crossover"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "167"
        ]
      },
      "source": [
        "#### Crossing Statement Lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "168"
        ]
      },
      "source": [
        "Applied on programs, a crossover mutation takes two parents and \"crosses\" a list of statements. As an example, if our \"parents\" `p1()` and `p2()` are defined as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "169"
        ]
      },
      "outputs": [],
      "source": [
        "def p1():  # type: ignore\n",
        "    a = 1\n",
        "    b = 2\n",
        "    c = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "170"
        ]
      },
      "outputs": [],
      "source": [
        "def p2():  # type: ignore\n",
        "    x = 1\n",
        "    y = 2\n",
        "    z = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "171"
        ]
      },
      "source": [
        "Then a crossover operation would produce one child with a body\n",
        "\n",
        "```python\n",
        "a = 1\n",
        "y = 2\n",
        "z = 3\n",
        "```\n",
        "\n",
        "and another child with a body\n",
        "\n",
        "```python\n",
        "x = 1\n",
        "b = 2\n",
        "c = 3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "172"
        ]
      },
      "source": [
        "We can easily implement this in a `CrossoverOperator` class in a method `cross_bodies()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "173"
        ]
      },
      "outputs": [],
      "source": [
        "class CrossoverOperator:\n",
        "    \"\"\"A class for performing statement crossover of Python programs\"\"\"\n",
        "\n",
        "    def __init__(self, log: Union[bool, int] = False):\n",
        "        \"\"\"Constructor. If `log` is set, turn on logging.\"\"\"\n",
        "        self.log = log\n",
        "\n",
        "    def cross_bodies(self, body_1: List[ast.AST], body_2: List[ast.AST]) -> \\\n",
        "        Tuple[List[ast.AST], List[ast.AST]]:\n",
        "        \"\"\"Crossover the statement lists `body_1` x `body_2`. Return new lists.\"\"\"\n",
        "\n",
        "        assert isinstance(body_1, list)\n",
        "        assert isinstance(body_2, list)\n",
        "\n",
        "        crossover_point_1 = len(body_1) // 2\n",
        "        crossover_point_2 = len(body_2) // 2\n",
        "        return (body_1[:crossover_point_1] + body_2[crossover_point_2:],\n",
        "                body_2[:crossover_point_2] + body_1[crossover_point_1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "174"
        ]
      },
      "source": [
        "Here's the `CrossoverOperatorMutator` applied on `p1` and `p2`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "175"
        ]
      },
      "outputs": [],
      "source": [
        "tree_p1: ast.Module = ast.parse(inspect.getsource(p1))\n",
        "tree_p2: ast.Module = ast.parse(inspect.getsource(p2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "176"
        ]
      },
      "outputs": [],
      "source": [
        "body_p1 = tree_p1.body[0].body  # type: ignore\n",
        "body_p2 = tree_p2.body[0].body  # type: ignore\n",
        "body_p1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "177"
        ]
      },
      "outputs": [],
      "source": [
        "crosser = CrossoverOperator()\n",
        "tree_p1.body[0].body, tree_p2.body[0].body = crosser.cross_bodies(body_p1, body_p2)  # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "178"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(tree_p1), '.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "179"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(tree_p2), '.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "180"
        ]
      },
      "source": [
        "#### Applying Crossover on Programs\n",
        "\n",
        "Applying the crossover operation on arbitrary programs is a bit more complex, though. We first have to _find_ lists of statements that we actually can cross over. The `can_cross()` method returns True if we have a list of statements that we can cross. Python modules and classes are excluded, because changing the ordering of definitions will not have much impact on the program functionality, other than introducing errors due to  dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "181"
        ]
      },
      "outputs": [],
      "source": [
        "class CrossoverOperator(CrossoverOperator):\n",
        "    # In modules and class defs, the ordering of elements does not matter (much)\n",
        "    SKIP_LIST = {ast.Module, ast.ClassDef}\n",
        "\n",
        "    def can_cross(self, tree: ast.AST, body_attr: str = 'body') -> bool:\n",
        "        if any(isinstance(tree, cls) for cls in self.SKIP_LIST):\n",
        "            return False\n",
        "\n",
        "        body = getattr(tree, body_attr, [])\n",
        "        return body is not None and len(body) >= 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "182"
        ]
      },
      "source": [
        "Here comes our method `crossover_attr()` which searches for crossover possibilities. It takes two ASTs `t1` and `t2` and an attribute (typically `'body'`) and retrieves the attribute lists $l_1$ (from `t1.<attr>`) and $l_2$ (from `t2.<attr>`).\n",
        "\n",
        "If $l_1$ and $l_2$ can be crossed, it crosses them, and is done. Otherwise\n",
        "\n",
        "* If there is a pair of elements $e_1 \\in l_1$ and $e_2 \\in l_2$ that has the same name \u2013 say, functions of the same name \u2013, it applies itself to $e_1$ and $e_2$.\n",
        "* Otherwise, it creates random pairs of elements $e_1 \\in l_1$ and $e_2 \\in l_2$ and applies itself on these very pairs.\n",
        "\n",
        "`crossover_attr()` changes `t1` and `t2` in place and returns True if a crossover was found; it returns False otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "183"
        ]
      },
      "outputs": [],
      "source": [
        "class CrossoverOperator(CrossoverOperator):\n",
        "    def crossover_attr(self, t1: ast.AST, t2: ast.AST, body_attr: str) -> bool:\n",
        "        \"\"\"\n",
        "        Crossover the bodies `body_attr` of two trees `t1` and `t2`.\n",
        "        Return True if successful.\n",
        "        \"\"\"\n",
        "        assert isinstance(t1, ast.AST)\n",
        "        assert isinstance(t2, ast.AST)\n",
        "        assert isinstance(body_attr, str)\n",
        "\n",
        "        if not getattr(t1, body_attr, None) or not getattr(t2, body_attr, None):\n",
        "            return False\n",
        "\n",
        "        if self.crossover_branches(t1, t2):\n",
        "            return True\n",
        "\n",
        "        if self.log > 1:\n",
        "            print(f\"Checking {t1}.{body_attr} x {t2}.{body_attr}\")\n",
        "\n",
        "        body_1 = getattr(t1, body_attr)\n",
        "        body_2 = getattr(t2, body_attr)\n",
        "\n",
        "        # If both trees have the attribute, we can cross their bodies\n",
        "        if self.can_cross(t1, body_attr) and self.can_cross(t2, body_attr):\n",
        "            if self.log:\n",
        "                print(f\"Crossing {t1}.{body_attr} x {t2}.{body_attr}\")\n",
        "\n",
        "            new_body_1, new_body_2 = self.cross_bodies(body_1, body_2)\n",
        "            setattr(t1, body_attr, new_body_1)\n",
        "            setattr(t2, body_attr, new_body_2)\n",
        "            return True\n",
        "\n",
        "        # Strategy 1: Find matches in class/function of same name\n",
        "        for child_1 in body_1:\n",
        "            if hasattr(child_1, 'name'):\n",
        "                for child_2 in body_2:\n",
        "                    if (hasattr(child_2, 'name') and\n",
        "                           child_1.name == child_2.name):\n",
        "                        if self.crossover_attr(child_1, child_2, body_attr):\n",
        "                            return True\n",
        "\n",
        "        # Strategy 2: Find matches anywhere\n",
        "        for child_1 in random.sample(body_1, len(body_1)):\n",
        "            for child_2 in random.sample(body_2, len(body_2)):\n",
        "                if self.crossover_attr(child_1, child_2, body_attr):\n",
        "                    return True\n",
        "\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "184"
        ]
      },
      "source": [
        "We have a special case for `if` nodes, where we can cross their body and `else` branches. (In Python, `for` and `while` also have `else` branches, but swapping these with loop bodies is likely to create havoc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "185"
        ]
      },
      "outputs": [],
      "source": [
        "class CrossoverOperator(CrossoverOperator):\n",
        "    def crossover_branches(self, t1: ast.AST, t2: ast.AST) -> bool:\n",
        "        \"\"\"Special case:\n",
        "        `t1` = `if P: S1 else: S2` x `t2` = `if P': S1' else: S2'`\n",
        "        becomes\n",
        "        `t1` = `if P: S2' else: S1'` and `t2` = `if P': S2 else: S1`\n",
        "        Returns True if successful.\n",
        "        \"\"\"\n",
        "        assert isinstance(t1, ast.AST)\n",
        "        assert isinstance(t2, ast.AST)\n",
        "\n",
        "        if (hasattr(t1, 'body') and hasattr(t1, 'orelse') and\n",
        "            hasattr(t2, 'body') and hasattr(t2, 'orelse')):\n",
        "\n",
        "            t1 = cast(ast.If, t1)  # keep mypy happy\n",
        "            t2 = cast(ast.If, t2)\n",
        "\n",
        "            if self.log:\n",
        "                print(f\"Crossing branches {t1} x {t2}\")\n",
        "\n",
        "            t1.body, t1.orelse, t2.body, t2.orelse = \\\n",
        "                t2.orelse, t2.body, t1.orelse, t1.body\n",
        "            return True\n",
        "\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "186"
        ]
      },
      "source": [
        "The method `crossover()` is the main entry point. It checks for the special `if` case as described above; if not, it searches for possible crossover points. It raises `CrossoverError` if not successful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "187"
        ]
      },
      "outputs": [],
      "source": [
        "class CrossoverOperator(CrossoverOperator):\n",
        "    def crossover(self, t1: ast.AST, t2: ast.AST) -> Tuple[ast.AST, ast.AST]:\n",
        "        \"\"\"Do a crossover of ASTs `t1` and `t2`.\n",
        "        Raises `CrossoverError` if no crossover is found.\"\"\"\n",
        "        assert isinstance(t1, ast.AST)\n",
        "        assert isinstance(t2, ast.AST)\n",
        "\n",
        "        for body_attr in ['body', 'orelse', 'finalbody']:\n",
        "            if self.crossover_attr(t1, t2, body_attr):\n",
        "                return t1, t2\n",
        "\n",
        "        raise CrossoverError(\"No crossover found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "188"
        ]
      },
      "outputs": [],
      "source": [
        "class CrossoverError(ValueError):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "189"
        ]
      },
      "source": [
        "### End of Excursion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "190"
        ]
      },
      "source": [
        "### Crossover in Action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "191"
        ]
      },
      "source": [
        "Let us put our `CrossoverOperator` in action. Here is a test case for crossover, involving more deeply nested structures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "192"
        ]
      },
      "outputs": [],
      "source": [
        "def p1():  # type: ignore\n",
        "    if True:\n",
        "        print(1)\n",
        "        print(2)\n",
        "        print(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "193"
        ]
      },
      "outputs": [],
      "source": [
        "def p2():  # type: ignore\n",
        "    if True:\n",
        "        print(a)\n",
        "        print(b)\n",
        "    else:\n",
        "        print(c)\n",
        "        print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "194"
        ]
      },
      "source": [
        "We invoke the `crossover()` method with two ASTs from `p1` and `p2`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "195"
        ]
      },
      "outputs": [],
      "source": [
        "crossover = CrossoverOperator()\n",
        "tree_p1 = ast.parse(inspect.getsource(p1))\n",
        "tree_p2 = ast.parse(inspect.getsource(p2))\n",
        "crossover.crossover(tree_p1, tree_p2);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "196"
        ]
      },
      "source": [
        "Here is the crossed offspring, mixing statement lists of `p1` and `p2`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "197"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(tree_p1), '.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "198"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(tree_p2), '.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "199"
        ]
      },
      "source": [
        "Here is our special case for `if` nodes in action, crossing our `middle()` tree with `p2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "200"
        ]
      },
      "outputs": [],
      "source": [
        "middle_t1, middle_t2 = crossover.crossover(middle_tree(),\n",
        "                                          ast.parse(inspect.getsource(p2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "201"
        ]
      },
      "source": [
        "We see how the resulting offspring encompasses elements of both sources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "202"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(middle_t1), '.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "203"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(middle_t2), '.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "204"
        ]
      },
      "source": [
        "## A Repairer Class\n",
        "\n",
        "So far, we have applied all our techniques on the `middle()` program only. Let us now create a `Repairer` class that applies automatic program repair on arbitrary Python programs. The idea is that you can apply it on some statistical debugger, for which you have gathered passing and failing test cases, and then invoke its `repair()` method to find a \"best\" fix candidate:\n",
        "\n",
        "```python\n",
        "debugger = OchiaiDebugger()\n",
        "with debugger:\n",
        "    <passing test>\n",
        "with debugger:\n",
        "    <failing test>\n",
        "...\n",
        "repairer = Repairer(debugger)\n",
        "repairer.repair()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "205"
        ]
      },
      "source": [
        "### Excursion: Implementing Repairer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "206"
        ]
      },
      "source": [
        "The main argument to the `Repairer` constructor is the `debugger` to get information from. On top of that, it also allows customizing the classes used for mutation, crossover, and reduction.\n",
        "Setting `targets` allows defining a set of functions to repair; setting `sources` allows setting a set of sources to take repairs from.\n",
        "The constructor then sets up the environment for running tests and repairing, as described below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "207"
        ]
      },
      "outputs": [],
      "source": [
        "from StackInspector import StackInspector  # minor dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "208"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(StackInspector):\n",
        "    \"\"\"A class for automatic repair of Python programs\"\"\"\n",
        "\n",
        "    def __init__(self, debugger: RankingDebugger, *,\n",
        "                 targets: Optional[List[Any]] = None,\n",
        "                 sources: Optional[List[Any]] = None,\n",
        "                 log: Union[bool, int] = False,\n",
        "                 mutator_class: Type = StatementMutator,\n",
        "                 crossover_class: Type = CrossoverOperator,\n",
        "                 reducer_class: Type = DeltaDebugger,\n",
        "                 globals: Optional[Dict[str, Any]] = None):\n",
        "        \"\"\"Constructor.\n",
        "`debugger`: a `RankingDebugger` to take tests and coverage from.\n",
        "`targets`: a list of functions/modules to be repaired.\n",
        "    (default: the covered functions in `debugger`, except tests)\n",
        "`sources`: a list of functions/modules to take repairs from.\n",
        "    (default: same as `targets`)\n",
        "`globals`: if given, a `globals()` dict for executing targets\n",
        "    (default: `globals()` of caller)\"\"\"\n",
        "\n",
        "        assert isinstance(debugger, RankingDebugger)\n",
        "        self.debugger = debugger\n",
        "        self.log = log\n",
        "\n",
        "        if targets is None:\n",
        "            targets = self.default_functions()\n",
        "        if not targets:\n",
        "            raise ValueError(\"No targets to repair\")\n",
        "\n",
        "        if sources is None:\n",
        "            sources = self.default_functions()\n",
        "        if not sources:\n",
        "            raise ValueError(\"No sources to take repairs from\")\n",
        "\n",
        "        if self.debugger.function() is None:\n",
        "            raise ValueError(\"Multiple entry points observed\")\n",
        "\n",
        "        self.target_tree: ast.AST = self.parse(targets)\n",
        "        self.source_tree: ast.AST = self.parse(sources)\n",
        "\n",
        "        self.log_tree(\"Target code to be repaired:\", self.target_tree)\n",
        "        if ast.dump(self.target_tree) != ast.dump(self.source_tree):\n",
        "            self.log_tree(\"Source code to take repairs from:\", \n",
        "                          self.source_tree)\n",
        "\n",
        "        self.fitness_cache: Dict[str, float] = {}\n",
        "\n",
        "        self.mutator: StatementMutator = \\\n",
        "            mutator_class(\n",
        "                source=all_statements(self.source_tree),\n",
        "                suspiciousness_func=self.debugger.suspiciousness,\n",
        "                log=(self.log >= 3))\n",
        "        self.crossover: CrossoverOperator = crossover_class(log=(self.log >= 3))\n",
        "        self.reducer: DeltaDebugger = reducer_class(log=(self.log >= 3))\n",
        "\n",
        "        if globals is None:\n",
        "            globals = self.caller_globals()  # see below\n",
        "\n",
        "        self.globals = globals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "209"
        ]
      },
      "source": [
        "When we access or execute functions, we do so in the  caller's environment, not ours. The `caller_globals()` method from `StackInspector` acts as replacement for `globals()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "210"
        ]
      },
      "source": [
        "#### Helper Functions\n",
        "\n",
        "The constructor uses a number of helper functions to create its environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "211"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def getsource(self, item: Union[str, Any]) -> str:\n",
        "        \"\"\"Get the source for `item`. Can also be a string.\"\"\"\n",
        "\n",
        "        if isinstance(item, str):\n",
        "            item = self.globals[item]\n",
        "        return inspect.getsource(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "212"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def default_functions(self) -> List[Callable]:\n",
        "        \"\"\"Return the set of functions to be repaired.\n",
        "        Functions whose names start or end in `test` are excluded.\"\"\"\n",
        "        def is_test(name: str) -> bool:\n",
        "            return name.startswith('test') or name.endswith('test')\n",
        "\n",
        "        return [func for func in self.debugger.covered_functions()\n",
        "                if not is_test(func.__name__)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "213"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def log_tree(self, description: str, tree: Any) -> None:\n",
        "        \"\"\"Print out `tree` as source code prefixed by `description`.\"\"\"\n",
        "        if self.log:\n",
        "            print(description)\n",
        "            print_content(ast.unparse(tree), '.py')\n",
        "            print()\n",
        "            print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "214"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def parse(self, items: List[Any]) -> ast.AST:\n",
        "        \"\"\"Read in a list of items into a single tree\"\"\"\n",
        "        tree = ast.parse(\"\")\n",
        "        for item in items:\n",
        "            if isinstance(item, str):\n",
        "                item = self.globals[item]\n",
        "\n",
        "            item_lines, item_first_lineno = inspect.getsourcelines(item)\n",
        "\n",
        "            try:\n",
        "                item_tree = ast.parse(\"\".join(item_lines))\n",
        "            except IndentationError:\n",
        "                # inner function or likewise\n",
        "                warnings.warn(f\"Can't parse {item.__name__}\")\n",
        "                continue\n",
        "\n",
        "            ast.increment_lineno(item_tree, item_first_lineno - 1)\n",
        "            tree.body += item_tree.body\n",
        "\n",
        "        return tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "215"
        ]
      },
      "source": [
        "#### Running Tests\n",
        "\n",
        "Now that we have set the environment for `Repairer`, we can implement one step of automatic repair after the other. The method `run_test_set()` runs the given `test_set` (`DifferenceDebugger.PASS` or `DifferenceDebugger.FAIL`), returning the number of passed tests. If `validate` is set, it checks whether the outcomes are as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "216"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def run_test_set(self, test_set: str, validate: bool = False) -> int:\n",
        "        \"\"\"\n",
        "        Run given `test_set`\n",
        "        (`DifferenceDebugger.PASS` or `DifferenceDebugger.FAIL`).\n",
        "        If `validate` is set, check expectations.\n",
        "        Return number of passed tests.\n",
        "        \"\"\"\n",
        "        passed = 0\n",
        "        collectors = self.debugger.collectors[test_set]\n",
        "        function = self.debugger.function()\n",
        "        assert function is not None\n",
        "        # FIXME: function may have been redefined\n",
        "\n",
        "        for c in collectors:\n",
        "            if self.log >= 4:\n",
        "                print(f\"Testing {c.id()}...\", end=\"\")\n",
        "\n",
        "            try:\n",
        "                function(**c.args())\n",
        "            except Exception as err:\n",
        "                if self.log >= 4:\n",
        "                    print(f\"failed ({err.__class__.__name__})\")\n",
        "\n",
        "                if validate and test_set == self.debugger.PASS:\n",
        "                    raise err.__class__(\n",
        "                        f\"{c.id()} should have passed, but failed\")\n",
        "                continue\n",
        "\n",
        "            passed += 1\n",
        "            if self.log >= 4:\n",
        "                print(\"passed\")\n",
        "\n",
        "            if validate and test_set == self.debugger.FAIL:\n",
        "                raise FailureNotReproducedError(\n",
        "                    f\"{c.id()} should have failed, but passed\")\n",
        "\n",
        "        return passed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "217"
        ]
      },
      "outputs": [],
      "source": [
        "class FailureNotReproducedError(ValueError):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "218"
        ]
      },
      "source": [
        "Here is how we use `run_tests_set()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "219"
        ]
      },
      "outputs": [],
      "source": [
        "repairer = Repairer(middle_debugger)\n",
        "assert repairer.run_test_set(middle_debugger.PASS) == \\\n",
        "    len(MIDDLE_PASSING_TESTCASES)\n",
        "assert repairer.run_test_set(middle_debugger.FAIL) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "220"
        ]
      },
      "source": [
        "The method `run_tests()` runs passing and failing tests, weighing the passed test cases to obtain the overall fitness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "221"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def weight(self, test_set: str) -> float:\n",
        "        \"\"\"\n",
        "        Return the weight of `test_set`\n",
        "        (`DifferenceDebugger.PASS` or `DifferenceDebugger.FAIL`).\n",
        "        \"\"\"\n",
        "        return {\n",
        "            self.debugger.PASS: WEIGHT_PASSING,\n",
        "            self.debugger.FAIL: WEIGHT_FAILING\n",
        "        }[test_set]\n",
        "\n",
        "    def run_tests(self, validate: bool = False) -> float:\n",
        "        \"\"\"Run passing and failing tests, returning weighted fitness.\"\"\"\n",
        "        fitness = 0.0\n",
        "\n",
        "        for test_set in [self.debugger.PASS, self.debugger.FAIL]:\n",
        "            passed = self.run_test_set(test_set, validate=validate)\n",
        "            ratio = passed / len(self.debugger.collectors[test_set])\n",
        "            fitness += self.weight(test_set) * ratio\n",
        "\n",
        "        return fitness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "222"
        ]
      },
      "source": [
        "The method `validate()` ensures the observed tests can be adequately reproduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "223"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def validate(self) -> None:\n",
        "        fitness = self.run_tests(validate=True)\n",
        "        assert fitness == self.weight(self.debugger.PASS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "224"
        ]
      },
      "outputs": [],
      "source": [
        "repairer = Repairer(middle_debugger)\n",
        "repairer.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "225"
        ]
      },
      "source": [
        "#### (Re)defining Functions\n",
        "\n",
        "Our `run_tests()` methods above do not yet redefine the function to be repaired. This is done by the `fitness()` function, which compiles and defines the given repair candidate `tree` before testing it.  It caches and returns the fitness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "226"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def fitness(self, tree: ast.AST) -> float:\n",
        "        \"\"\"Test `tree`, returning its fitness\"\"\"\n",
        "        key = cast(str, ast.dump(tree))\n",
        "        if key in self.fitness_cache:\n",
        "            return self.fitness_cache[key]\n",
        "\n",
        "        # Save defs\n",
        "        original_defs: Dict[str, Any] = {}\n",
        "        for name in self.toplevel_defs(tree):\n",
        "            if name in self.globals:\n",
        "                original_defs[name] = self.globals[name]\n",
        "            else:\n",
        "                warnings.warn(f\"Couldn't find definition of {repr(name)}\")\n",
        "\n",
        "        assert original_defs, f\"Couldn't find any definition\"\n",
        "\n",
        "        if self.log >= 3:\n",
        "            print(\"Repair candidate:\")\n",
        "            print_content(ast.unparse(tree), '.py')\n",
        "            print()\n",
        "\n",
        "        # Create new definition\n",
        "        try:\n",
        "            code = compile(cast(ast.Module, tree), '<Repairer>', 'exec')\n",
        "        except ValueError:  # Compilation error\n",
        "            code = None\n",
        "\n",
        "        if code is None:\n",
        "            if self.log >= 3:\n",
        "                print(f\"Fitness = 0.0 (compilation error)\")\n",
        "\n",
        "            fitness = 0.0\n",
        "            return fitness\n",
        "\n",
        "        # Execute new code, defining new functions in `self.globals`\n",
        "        exec(code, self.globals)\n",
        "\n",
        "        # Set new definitions in the namespace (`__globals__`)\n",
        "        # of the function we will be calling.\n",
        "        function = self.debugger.function()\n",
        "        assert function is not None\n",
        "        assert hasattr(function, '__globals__')\n",
        "\n",
        "        for name in original_defs:\n",
        "            function.__globals__[name] = self.globals[name]  # type: ignore\n",
        "\n",
        "        fitness = self.run_tests(validate=False)\n",
        "\n",
        "        # Restore definitions\n",
        "        for name in original_defs:\n",
        "            function.__globals__[name] = original_defs[name]  # type: ignore\n",
        "            self.globals[name] = original_defs[name]\n",
        "\n",
        "        if self.log >= 3:\n",
        "            print(f\"Fitness = {fitness}\")\n",
        "\n",
        "        self.fitness_cache[key] = fitness\n",
        "        return fitness"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "227"
        ]
      },
      "source": [
        "The helper function `toplevel_defs()` helps to save and restore the environment before and after redefining the function under repair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "228"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def toplevel_defs(self, tree: ast.AST) -> List[str]:\n",
        "        \"\"\"Return a list of names of defined functions and classes in `tree`\"\"\"\n",
        "        visitor = DefinitionVisitor()\n",
        "        visitor.visit(tree)\n",
        "        assert hasattr(visitor, 'definitions')\n",
        "        return visitor.definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "229"
        ]
      },
      "outputs": [],
      "source": [
        "class DefinitionVisitor(NodeVisitor):\n",
        "    def __init__(self) -> None:\n",
        "        self.definitions: List[str] = []\n",
        "\n",
        "    def add_definition(self, node: Union[ast.ClassDef, \n",
        "                                         ast.FunctionDef, \n",
        "                                         ast.AsyncFunctionDef]) -> None:\n",
        "        self.definitions.append(node.name)\n",
        "\n",
        "    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:\n",
        "        self.add_definition(node)\n",
        "\n",
        "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> None:\n",
        "        self.add_definition(node)\n",
        "\n",
        "    def visit_ClassDef(self, node: ast.ClassDef) -> None:\n",
        "        self.add_definition(node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "230"
        ]
      },
      "source": [
        "Here's an example for `fitness()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "231"
        ]
      },
      "outputs": [],
      "source": [
        "repairer = Repairer(middle_debugger, log=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "232"
        ]
      },
      "outputs": [],
      "source": [
        "good_fitness = repairer.fitness(middle_tree())\n",
        "good_fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "233"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert good_fitness >= 0.99, \"fitness() failed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "234"
        ]
      },
      "outputs": [],
      "source": [
        "bad_middle_tree = ast.parse(\"def middle(x, y, z): return x\")\n",
        "bad_fitness = repairer.fitness(bad_middle_tree)\n",
        "bad_fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "235"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert bad_fitness < 0.5, \"fitness() failed\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "236"
        ]
      },
      "source": [
        "#### Repairing\n",
        "\n",
        "Now for the actual `repair()` method, which creates a `population` and then evolves it until the fitness is 1.0 or the given number of iterations is spent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "237"
        ]
      },
      "outputs": [],
      "source": [
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "238"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def initial_population(self, size: int) -> List[ast.AST]:\n",
        "        \"\"\"Return an initial population of size `size`\"\"\"\n",
        "        return [self.target_tree] + \\\n",
        "            [self.mutator.mutate(copy.deepcopy(self.target_tree))\n",
        "                for i in range(size - 1)]\n",
        "\n",
        "    def repair(self, population_size: int = POPULATION_SIZE, iterations: int = 100) -> \\\n",
        "        Tuple[ast.AST, float]:\n",
        "        \"\"\"\n",
        "        Repair the function we collected test runs from.\n",
        "        Use a population size of `population_size` and\n",
        "        at most `iterations` iterations.\n",
        "        Returns a pair (`ast`, `fitness`) where \n",
        "        `ast` is the AST of the repaired function, and\n",
        "        `fitness` is its fitness (between 0 and 1.0)\n",
        "        \"\"\"\n",
        "        self.validate()\n",
        "\n",
        "        population = self.initial_population(population_size)\n",
        "\n",
        "        last_key = ast.dump(self.target_tree)\n",
        "\n",
        "        for iteration in range(iterations):\n",
        "            population = self.evolve(population)\n",
        "\n",
        "            best_tree = population[0]\n",
        "            fitness = self.fitness(best_tree)\n",
        "\n",
        "            if self.log:\n",
        "                print(f\"Evolving population: \"\n",
        "                      f\"iteration{iteration:4}/{iterations} \"\n",
        "                      f\"fitness = {fitness:.5}   \\r\", end=\"\")\n",
        "\n",
        "            if self.log >= 2:\n",
        "                best_key = ast.dump(best_tree)\n",
        "                if best_key != last_key:\n",
        "                    print()\n",
        "                    print()\n",
        "                    self.log_tree(f\"New best code (fitness = {fitness}):\",\n",
        "                                  best_tree)\n",
        "                    last_key = best_key\n",
        "\n",
        "            if fitness >= 1.0:\n",
        "                break\n",
        "\n",
        "        if self.log:\n",
        "            print()\n",
        "\n",
        "        if self.log and self.log < 2:\n",
        "            self.log_tree(f\"Best code (fitness = {fitness}):\", best_tree)\n",
        "\n",
        "        best_tree = self.reduce(best_tree)\n",
        "        fitness = self.fitness(best_tree)\n",
        "\n",
        "        self.log_tree(f\"Reduced code (fitness = {fitness}):\", best_tree)\n",
        "\n",
        "        return best_tree, fitness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "239"
        ]
      },
      "source": [
        "#### Evolving\n",
        "\n",
        "The evolution of our population takes place in the `evolve()` method. In contrast to the `evolve_middle()` function, above, we use crossover to create the offspring, which we still mutate afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "240"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def evolve(self, population: List[ast.AST]) -> List[ast.AST]:\n",
        "        \"\"\"Evolve the candidate population by mutating and crossover.\"\"\"\n",
        "        n = len(population)\n",
        "\n",
        "        # Create offspring as crossover of parents\n",
        "        offspring: List[ast.AST] = []\n",
        "        while len(offspring) < n:\n",
        "            parent_1 = copy.deepcopy(random.choice(population))\n",
        "            parent_2 = copy.deepcopy(random.choice(population))\n",
        "            try:\n",
        "                self.crossover.crossover(parent_1, parent_2)\n",
        "            except CrossoverError:\n",
        "                pass  # Just keep parents\n",
        "            offspring += [parent_1, parent_2]\n",
        "\n",
        "        # Mutate offspring\n",
        "        offspring = [self.mutator.mutate(tree) for tree in offspring]\n",
        "\n",
        "        # Add it to population\n",
        "        population += offspring\n",
        "\n",
        "        # Keep the fitter part of the population\n",
        "        population.sort(key=self.fitness_key, reverse=True)\n",
        "        population = population[:n]\n",
        "\n",
        "        return population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "241"
        ]
      },
      "source": [
        "A second difference is that we not only sort by fitness, but also by tree size \u2013\u00a0with equal fitness, a smaller tree thus will be favored. This helps keeping fixes and patches small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "242"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def fitness_key(self, tree: ast.AST) -> Tuple[float, int]:\n",
        "        \"\"\"Key to be used for sorting the population\"\"\"\n",
        "        tree_size = len([node for node in ast.walk(tree)])\n",
        "        return (self.fitness(tree), -tree_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "243"
        ]
      },
      "source": [
        "#### Simplifying\n",
        "\n",
        "The last step in repairing is simplifying the code. As demonstrated in the chapter on [reducing failure-inducing inputs](DeltaDebugger.ipynb), we can use delta debugging on code to get rid of superfluous statements. To this end, we convert the tree to lines, run delta debugging on them, and then convert it back to a tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "244"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def reduce(self, tree: ast.AST) -> ast.AST:\n",
        "        \"\"\"Simplify `tree` using delta debugging.\"\"\"\n",
        "\n",
        "        original_fitness = self.fitness(tree)\n",
        "        source_lines = ast.unparse(tree).split('\\n')\n",
        "\n",
        "        with self.reducer:\n",
        "            self.test_reduce(source_lines, original_fitness)\n",
        "\n",
        "        reduced_lines = self.reducer.min_args()['source_lines']\n",
        "        reduced_source = \"\\n\".join(reduced_lines)\n",
        "\n",
        "        return ast.parse(reduced_source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "245"
        ]
      },
      "source": [
        "As dicussed above, we simplify the code by having the test function (`test_reduce()`) declare reaching the maximum fitness obtained so far as a \"failure\". Delta debugging will then simplify the input as long as the \"failure\" (and hence the maximum fitness obtained) persists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "246"
        ]
      },
      "outputs": [],
      "source": [
        "class Repairer(Repairer):\n",
        "    def test_reduce(self, source_lines: List[str], original_fitness: float) -> None:\n",
        "        \"\"\"Test function for delta debugging.\"\"\"\n",
        "\n",
        "        try:\n",
        "            source = \"\\n\".join(source_lines)\n",
        "            tree = ast.parse(source)\n",
        "            fitness = self.fitness(tree)\n",
        "            assert fitness < original_fitness\n",
        "\n",
        "        except AssertionError:\n",
        "            raise\n",
        "        except SyntaxError:\n",
        "            raise\n",
        "        except IndentationError:\n",
        "            raise\n",
        "        except Exception:\n",
        "            # traceback.print_exc()  # Uncomment to see internal errors\n",
        "            raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "247"
        ]
      },
      "source": [
        "### End of Excursion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "248"
        ]
      },
      "source": [
        "### Repairer in Action\n",
        "\n",
        "Let us go and apply `Repairer` in practice. We initialize it with `middle_debugger`, which has (still) collected the passing and failing runs for `middle_test()`. We also set `log` for some diagnostics along the way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "249"
        ]
      },
      "outputs": [],
      "source": [
        "repairer = Repairer(middle_debugger, log=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "250"
        ]
      },
      "source": [
        "We now invoke `repair()` to evolve our population. After a few iterations, we find a tree with perfect fitness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "251"
        ]
      },
      "outputs": [],
      "source": [
        "best_tree, fitness = repairer.repair()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "252"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(best_tree), '.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "253"
        ]
      },
      "outputs": [],
      "source": [
        "fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "254"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert fitness >= 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "255"
        ]
      },
      "source": [
        "Again, we have a perfect solution. Here, we did not even need to simplify the code in the last iteration, as our `fitness_key()` function favors smaller implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "256"
        ]
      },
      "source": [
        "## Removing HTML Markup\n",
        "\n",
        "Let us apply `Repairer` on our other ongoing example, namely `remove_html_markup()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "257"
        ]
      },
      "outputs": [],
      "source": [
        "def remove_html_markup(s):  # type: ignore\n",
        "    tag = False\n",
        "    quote = False\n",
        "    out = \"\"\n",
        "\n",
        "    for c in s:\n",
        "        if c == '<' and not quote:\n",
        "            tag = True\n",
        "        elif c == '>' and not quote:\n",
        "            tag = False\n",
        "        elif c == '\"' or c == \"'\" and tag:\n",
        "            quote = not quote\n",
        "        elif not tag:\n",
        "            out = out + c\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "258"
        ]
      },
      "outputs": [],
      "source": [
        "def remove_html_markup_tree() -> ast.AST:\n",
        "    return ast.parse(inspect.getsource(remove_html_markup))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "259"
        ]
      },
      "source": [
        "To run `Repairer` on `remove_html_markup()`, we need a test and a test suite. `remove_html_markup_test()` raises an exception if applying `remove_html_markup()` on the given `html` string does not yield the `plain` string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "260"
        ]
      },
      "outputs": [],
      "source": [
        "def remove_html_markup_test(html: str, plain: str) -> None:\n",
        "    outcome = remove_html_markup(html)\n",
        "    assert outcome == plain, \\\n",
        "        f\"Got {repr(outcome)}, expected {repr(plain)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "261"
        ]
      },
      "source": [
        "Now for the test suite. We use a simple fuzzing scheme to create dozens of passing and failing test cases in `REMOVE_HTML_PASSING_TESTCASES` and `REMOVE_HTML_FAILING_TESTCASES`, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "262"
        ]
      },
      "source": [
        "### Excursion: Creating HTML Test Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "263"
        ]
      },
      "outputs": [],
      "source": [
        "def random_string(length: int = 5, start: int = ord(' '), end: int = ord('~')) -> str:\n",
        "    return \"\".join(chr(random.randrange(start, end + 1)) for i in range(length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "264"
        ]
      },
      "outputs": [],
      "source": [
        "random_string()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "265"
        ]
      },
      "outputs": [],
      "source": [
        "def random_id(length: int = 2) -> str:\n",
        "    return random_string(start=ord('a'), end=ord('z'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "266"
        ]
      },
      "outputs": [],
      "source": [
        "random_id()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "267"
        ]
      },
      "outputs": [],
      "source": [
        "def random_plain() -> str:\n",
        "    return random_string().replace('<', '').replace('>', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "268"
        ]
      },
      "outputs": [],
      "source": [
        "def random_string_noquotes() -> str:\n",
        "    return random_string().replace('\"', '').replace(\"'\", '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "269"
        ]
      },
      "outputs": [],
      "source": [
        "def random_html(depth: int = 0) -> Tuple[str, str]:\n",
        "    prefix = random_plain()\n",
        "    tag = random_id()\n",
        "\n",
        "    if depth > 0:\n",
        "        html, plain = random_html(depth - 1)\n",
        "    else:\n",
        "        html = plain = random_plain()\n",
        "\n",
        "    attr = random_id()\n",
        "    value = '\"' + random_string_noquotes() + '\"'\n",
        "    postfix = random_plain()\n",
        "\n",
        "    return f'{prefix}<{tag} {attr}={value}>{html}</{tag}>{postfix}', \\\n",
        "        prefix + plain + postfix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "270"
        ]
      },
      "outputs": [],
      "source": [
        "random_html()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "271"
        ]
      },
      "outputs": [],
      "source": [
        "def remove_html_testcase(expected: bool = True) -> Tuple[str, str]:\n",
        "    while True:\n",
        "        html, plain = random_html()\n",
        "        outcome = (remove_html_markup(html) == plain)\n",
        "        if outcome == expected:\n",
        "            return html, plain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "272"
        ]
      },
      "outputs": [],
      "source": [
        "REMOVE_HTML_TESTS = 100\n",
        "REMOVE_HTML_PASSING_TESTCASES = \\\n",
        "    [remove_html_testcase(True) for i in range(REMOVE_HTML_TESTS)]\n",
        "REMOVE_HTML_FAILING_TESTCASES = \\\n",
        "    [remove_html_testcase(False) for i in range(REMOVE_HTML_TESTS)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "273"
        ]
      },
      "source": [
        "### End of Excursion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "274"
        ]
      },
      "source": [
        "Here is a passing test case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "275"
        ]
      },
      "outputs": [],
      "source": [
        "REMOVE_HTML_PASSING_TESTCASES[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "276"
        ]
      },
      "outputs": [],
      "source": [
        "html, plain = REMOVE_HTML_PASSING_TESTCASES[0]\n",
        "remove_html_markup_test(html, plain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "277"
        ]
      },
      "source": [
        "Here is a failing test case (containing a double quote in the plain text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "278"
        ]
      },
      "outputs": [],
      "source": [
        "REMOVE_HTML_FAILING_TESTCASES[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "279"
        ]
      },
      "outputs": [],
      "source": [
        "with ExpectError():\n",
        "    html, plain = REMOVE_HTML_FAILING_TESTCASES[0]\n",
        "    remove_html_markup_test(html, plain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "280"
        ]
      },
      "source": [
        "We run our tests, collecting the outcomes in `html_debugger`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "281"
        ]
      },
      "outputs": [],
      "source": [
        "html_debugger = OchiaiDebugger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "282"
        ]
      },
      "outputs": [],
      "source": [
        "for html, plain in (REMOVE_HTML_PASSING_TESTCASES + \n",
        "                    REMOVE_HTML_FAILING_TESTCASES):\n",
        "    with html_debugger:\n",
        "        remove_html_markup_test(html, plain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "283"
        ]
      },
      "source": [
        "The suspiciousness distribution will not be of much help here\u00a0\u2013\u00a0pretty much all lines in `remove_html_markup()` have the same suspiciousness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "284"
        ]
      },
      "outputs": [],
      "source": [
        "html_debugger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "285"
        ]
      },
      "source": [
        "Let us create our repairer and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "286"
        ]
      },
      "outputs": [],
      "source": [
        "html_repairer = Repairer(html_debugger, log=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "287"
        ]
      },
      "outputs": [],
      "source": [
        "best_tree, fitness = html_repairer.repair(iterations=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "288"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert fitness < 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "289"
        ]
      },
      "source": [
        "We see that the \"best\" code is still our original code, with no changes. And we can set `iterations` to 50, 100, 200... \u2013\u00a0our `Repairer` won't be able to repair it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "290"
        ]
      },
      "outputs": [],
      "source": [
        "quiz(\"Why couldn't `Repairer()` repair `remove_html_markup()`?\",\n",
        "     [\n",
        "         \"The population is too small!\",\n",
        "         \"The suspiciousness is too evenly distributed!\",\n",
        "         \"We need more test cases!\",\n",
        "         \"We need more iterations!\",\n",
        "         \"There is no statement in the source with a correct condition!\",\n",
        "         \"The population is too big!\",\n",
        "     ], '5242880 >> 20')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "291"
        ]
      },
      "source": [
        "You can explore all the hypotheses above by changing the appropriate parameters, but you won't be able to change the outcome. The problem is that, unlike `middle()`, there is no statement (or combination thereof) in `remove_html_markup()` that could be used to make the failure go away. For this, we need to mutate another aspect of the code, which we will explore in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "292"
        ]
      },
      "source": [
        "## Mutating Conditions\n",
        "\n",
        "The `Repairer` class is very configurable. The individual steps in automated repair can all be replaced by providing own classes in the keyword arguments of its `__init__()` constructor:\n",
        "\n",
        "* To change fault localization, pass a different `debugger` that is a subclass of `RankingDebugger`.\n",
        "* To change the mutation operator, set `mutator_class` to a subclass of `StatementMutator`.\n",
        "* To change the crossover operator, set `crossover_class` to a subclass of `CrossoverOperator`.\n",
        "* To change the reduction algorithm, set `reducer_class` to a subclass of `Reducer`.\n",
        "\n",
        "In this section, we will explore how to extend the mutation operator such that it can mutate _conditions_ for control constructs such as `if`, `while`, or `for`. To this end, we introduce a new class `ConditionMutator` subclassing `StatementMutator`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "293"
        ]
      },
      "source": [
        "### Collecting Conditions\n",
        "\n",
        "Let us start with a few simple supporting functions. The function `all_conditions()` retrieves all control conditions from an AST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "294"
        ]
      },
      "outputs": [],
      "source": [
        "def all_conditions(trees: Union[ast.AST, List[ast.AST]],\n",
        "                   tp: Optional[Type] = None) -> List[ast.expr]:\n",
        "    \"\"\"\n",
        "    Return all conditions from the AST (or AST list) `trees`.\n",
        "    If `tp` is given, return only elements of that type.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(trees, list):\n",
        "        assert isinstance(trees, ast.AST)\n",
        "        trees = [trees]\n",
        "\n",
        "    visitor = ConditionVisitor()\n",
        "    for tree in trees:\n",
        "        visitor.visit(tree)\n",
        "    conditions = visitor.conditions\n",
        "    if tp is not None:\n",
        "        conditions = [c for c in conditions if isinstance(c, tp)]\n",
        "\n",
        "    return conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "295"
        ]
      },
      "source": [
        "`all_conditions()` uses a `ConditionVisitor` class to walk the tree and collect the conditions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "296"
        ]
      },
      "outputs": [],
      "source": [
        "class ConditionVisitor(NodeVisitor):\n",
        "    def __init__(self) -> None:\n",
        "        self.conditions: List[ast.expr] = []\n",
        "        self.conditions_seen: Set[str] = set()\n",
        "        super().__init__()\n",
        "\n",
        "    def add_conditions(self, node: ast.AST, attr: str) -> None:\n",
        "        elems = getattr(node, attr, [])\n",
        "        if not isinstance(elems, list):\n",
        "            elems = [elems]\n",
        "\n",
        "        elems = cast(List[ast.expr], elems)\n",
        "\n",
        "        for elem in elems:\n",
        "            elem_str = ast.unparse(elem)\n",
        "            if elem_str not in self.conditions_seen:\n",
        "                self.conditions.append(elem)\n",
        "                self.conditions_seen.add(elem_str)\n",
        "\n",
        "    def visit_BoolOp(self, node: ast.BoolOp) -> ast.AST:\n",
        "        self.add_conditions(node, 'values')\n",
        "        return super().generic_visit(node)\n",
        "\n",
        "    def visit_UnaryOp(self, node: ast.UnaryOp) -> ast.AST:\n",
        "        if isinstance(node.op, ast.Not):\n",
        "            self.add_conditions(node, 'operand')\n",
        "        return super().generic_visit(node)\n",
        "\n",
        "    def generic_visit(self, node: ast.AST) -> ast.AST:\n",
        "        if hasattr(node, 'test'):\n",
        "            self.add_conditions(node, 'test')\n",
        "        return super().generic_visit(node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "297"
        ]
      },
      "source": [
        "Here are all the conditions in `remove_html_markup()`. This is some material to construct new conditions from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "298"
        ]
      },
      "outputs": [],
      "source": [
        "[ast.unparse(cond).strip()\n",
        "    for cond in all_conditions(remove_html_markup_tree())]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "299"
        ]
      },
      "source": [
        "### Mutating Conditions\n",
        "\n",
        "Here comes our `ConditionMutator` class. We subclass from `StatementMutator` and set an attribute `self.conditions` containing all the conditions in the source. The method `choose_condition()` randomly picks a condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "300"
        ]
      },
      "outputs": [],
      "source": [
        "class ConditionMutator(StatementMutator):\n",
        "    \"\"\"Mutate conditions in an AST\"\"\"\n",
        "\n",
        "    def __init__(self, *args: Any, **kwargs: Any) -> None:\n",
        "        \"\"\"Constructor. Arguments are as with `StatementMutator` constructor.\"\"\"\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.conditions = all_conditions(self.source)\n",
        "        if self.log:\n",
        "            print(\"Found conditions\",\n",
        "                  [ast.unparse(cond).strip() \n",
        "                   for cond in self.conditions])\n",
        "\n",
        "    def choose_condition(self) -> ast.expr:\n",
        "        \"\"\"Return a random condition from source.\"\"\"\n",
        "        return copy.deepcopy(random.choice(self.conditions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "301"
        ]
      },
      "source": [
        "The actual mutation takes place in the `swap()` method. If the node to be replaced has a `test` attribute (i.e. a controlling predicate), then we pick a random condition `cond` from the source and randomly chose from:\n",
        "\n",
        "* **set**: We change `test` to `cond`.\n",
        "* **not**: We invert `test`.\n",
        "* **and**: We replace `test` by `cond and test`.\n",
        "* **or**: We replace `test` by `cond or test`.\n",
        "\n",
        "Over time, this might lead to operators propagating across the population."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "302"
        ]
      },
      "outputs": [],
      "source": [
        "class ConditionMutator(ConditionMutator):\n",
        "    def choose_bool_op(self) -> str:\n",
        "        return random.choice(['set', 'not', 'and', 'or'])\n",
        "\n",
        "    def swap(self, node: ast.AST) -> ast.AST:\n",
        "        \"\"\"Replace `node` condition by a condition from `source`\"\"\"\n",
        "        if not hasattr(node, 'test'):\n",
        "            return super().swap(node)\n",
        "\n",
        "        node = cast(ast.If, node)\n",
        "\n",
        "        cond = self.choose_condition()\n",
        "        new_test = None\n",
        "\n",
        "        choice = self.choose_bool_op()\n",
        "\n",
        "        if choice == 'set':\n",
        "            new_test = cond\n",
        "        elif choice == 'not':\n",
        "            new_test = ast.UnaryOp(op=ast.Not(), operand=node.test)\n",
        "        elif choice == 'and':\n",
        "            new_test = ast.BoolOp(op=ast.And(), values=[cond, node.test])\n",
        "        elif choice == 'or':\n",
        "            new_test = ast.BoolOp(op=ast.Or(), values=[cond, node.test])\n",
        "        else:\n",
        "            raise ValueError(\"Unknown boolean operand\")\n",
        "\n",
        "        if new_test:\n",
        "            # ast.copy_location(new_test, node)\n",
        "            node.test = new_test\n",
        "\n",
        "        return node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "303"
        ]
      },
      "source": [
        "We can use the mutator just like `StatementMutator`, except that some of the mutations will also include new conditions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "304"
        ]
      },
      "outputs": [],
      "source": [
        "mutator = ConditionMutator(source=all_statements(remove_html_markup_tree()),\n",
        "                           log=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "305"
        ]
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    new_tree = mutator.mutate(remove_html_markup_tree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "306"
        ]
      },
      "source": [
        "Let us put our new mutator to action, again in a `Repairer()`. To activate it, all we need to do is to pass it as `mutator_class` keyword argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "307"
        ]
      },
      "outputs": [],
      "source": [
        "condition_repairer = Repairer(html_debugger,\n",
        "                              mutator_class=ConditionMutator,\n",
        "                              log=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "308"
        ]
      },
      "source": [
        "We might need more iterations for this one. Let us see..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "309"
        ]
      },
      "outputs": [],
      "source": [
        "best_tree, fitness = condition_repairer.repair(iterations=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "310"
        ]
      },
      "outputs": [],
      "source": [
        "repaired_source = ast.unparse(best_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "311"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(repaired_source, '.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "312"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert fitness >= 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "313"
        ]
      },
      "source": [
        "Success again! We have automatically repaired `remove_html_markup()` \u2013 the resulting code passes all tests, including those that were previously failing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "314"
        ]
      },
      "source": [
        "Again, we can present the fix as a patch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "315"
        ]
      },
      "outputs": [],
      "source": [
        "original_source = ast.unparse(remove_html_markup_tree())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "316"
        ]
      },
      "outputs": [],
      "source": [
        "for patch in diff(original_source, repaired_source):\n",
        "    print_patch(patch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "317"
        ]
      },
      "source": [
        "However, looking at the patch, one may come up with doubts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "318"
        ]
      },
      "outputs": [],
      "source": [
        "quiz(\"Is this actually the best solution?\",\n",
        "    [\n",
        "        \"Yes, sure, of course. Why?\",\n",
        "        \"Err - what happened to single quotes?\"\n",
        "    ], 1 << 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "319"
        ]
      },
      "source": [
        "Indeed\u00a0\u2013 our solution does not seem to handle single quotes anymore. Why is that so?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "320"
        ]
      },
      "outputs": [],
      "source": [
        "quiz(\"Why aren't single quotes handled in the solution?\",\n",
        "    [\n",
        "        \"Because they're not important. \"\n",
        "            \"I mean, y'know, who uses 'em anyway?\",\n",
        "        \"Because they are not part of our tests? \"\n",
        "            \"Let me look up how they are constructed...\"\n",
        "    ], 1 << 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "321"
        ]
      },
      "source": [
        "Correct! Our test cases do not include single quotes \u2013\u00a0at least not in the interior of HTML tags \u2013 and thus, automatic repair did not care to preserve their handling."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "322"
        ]
      },
      "source": [
        "How can we fix this? An easy way is to include an appropriate test case in our set \u2013\u00a0a test case that passes with the original `remove_html_markup()`, yet fails with the \"repaired\" `remove_html_markup()` as shown above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "323"
        ]
      },
      "outputs": [],
      "source": [
        "with html_debugger:\n",
        "    remove_html_markup_test(\"<foo quote='>abc'>me</foo>\", \"me\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "324"
        ]
      },
      "source": [
        "Let us repeat the repair with the extended test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "325"
        ]
      },
      "outputs": [],
      "source": [
        "best_tree, fitness = condition_repairer.repair(iterations=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "326"
        ]
      },
      "source": [
        "Here is the final tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "327"
        ]
      },
      "outputs": [],
      "source": [
        "print_content(ast.unparse(best_tree), '.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "328"
        ]
      },
      "source": [
        "And here is its fitness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "329"
        ]
      },
      "outputs": [],
      "source": [
        "fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "330"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert fitness >= 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "331"
        ]
      },
      "source": [
        "The revised candidate now passes _all_ tests (including the tricky quote test we added last). Its condition now properly checks for `tag` _and_ both quotes. (The `tag` inside the parentheses is still redundant, but so be it.) From this example, we can learn a few lessons about the possibilities and risks of automated repair:\n",
        "\n",
        "* First, automatic repair is highly dependent on the quality of the checking tests. The risk is that the repair may overspecialize towards the test.\n",
        "* Second, when based on \"plastic surgery\", automated repair is highly dependent on the sources that program fragments are chosen from. If there is a hint of a solution somewhere in the code, there is a chance that automated repair will catch it up.\n",
        "* Third, automatic repair is a deeply heuristic approach. Its behavior will vary widely with any change to the parameters (and the underlying random number generators).\n",
        "* Fourth, automatic repair can take a long time. The examples we have in this chapter take less than a minute to compute, and neither Python nor our implementation is exactly fast. But as the search space grows, automated repair will take much longer.\n",
        "\n",
        "On the other hand, even an incomplete automated repair candidate can be much better than nothing at all \u2013\u00a0it may provide all the essential ingredients (such as the location or the involved variables) for a successful fix. When users of automated repair techniques are aware of its limitations and its assumptions, there is lots of potential in automated repair. Enjoy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "332"
        ]
      },
      "source": [
        "## Limitations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "333"
        ]
      },
      "source": [
        "The `Repairer` class is tested on our example programs, but not much more. Things that do not work include\n",
        "\n",
        "* Functions with inner functions are not repaired."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "334"
        ]
      },
      "source": [
        "## Synopsis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "335"
        ]
      },
      "source": [
        "This chapter provides tools and techniques for automated repair of program code. The `Repairer` class takes a `RankingDebugger` debugger as input (such as `OchiaiDebugger` from the [chapter on statistical debugging](StatisticalDebugger.ipynb). A typical setup looks like this:\n",
        "\n",
        "```python\n",
        "from debuggingbook.StatisticalDebugger import OchiaiDebugger\n",
        "\n",
        "debugger = OchiaiDebugger()\n",
        "for inputs in TESTCASES:\n",
        "    with debugger:\n",
        "        test_foo(inputs)\n",
        "...\n",
        "\n",
        "repairer = Repairer(debugger)\n",
        "```\n",
        "Here, `test_foo()` is a function that raises an exception if the tested function `foo()` fails. If `foo()` passes, `test_foo()` should not raise an exception."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "336"
        ]
      },
      "source": [
        "The `repair()` method of a `Repairer` searches for a repair of the code covered in the debugger (except for methods whose name starts or ends in `test`, such that `foo()`, not `test_foo()` is repaired). `repair()` returns the best fix candidate as a pair `(tree, fitness)` where `tree` is a [Python abstract syntax tree](http://docs.python.org/3/library/ast) (AST) of the fix candidate, and `fitness` is the fitness of the candidate (a value between 0 and 1). A `fitness` of 1.0 means that the candidate passed all tests. A typical usage looks like this:\n",
        "\n",
        "```python\n",
        "tree, fitness = repairer.repair()\n",
        "print(ast.unparse(tree), fitness)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "337"
        ]
      },
      "source": [
        "Here is a complete example for the `middle()` program. This is the original source code of `middle()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "338"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "print_content(middle_source, '.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "339"
        ]
      },
      "source": [
        "We set up a function `middle_test()` that tests it. The `middle_debugger`  collects testcases and outcomes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "340"
        ]
      },
      "outputs": [],
      "source": [
        "middle_debugger = OchiaiDebugger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "341"
        ]
      },
      "outputs": [],
      "source": [
        "for x, y, z in MIDDLE_PASSING_TESTCASES + MIDDLE_FAILING_TESTCASES:\n",
        "    with middle_debugger:\n",
        "        middle_test(x, y, z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "342"
        ]
      },
      "source": [
        "The repairer is instantiated with the debugger used (`middle_debugger`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "343"
        ]
      },
      "outputs": [],
      "source": [
        "middle_repairer = Repairer(middle_debugger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "344"
        ]
      },
      "source": [
        "The `repair()` method of the repairer attempts to repair the function invoked by the test (`middle()`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "345"
        ]
      },
      "outputs": [],
      "source": [
        "tree, fitness = middle_repairer.repair()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "346"
        ]
      },
      "source": [
        "The returned AST `tree` can be output via `ast.unparse()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "347"
        ]
      },
      "outputs": [],
      "source": [
        "print(ast.unparse(tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "348"
        ]
      },
      "source": [
        "The `fitness` value shows how well the repaired program fits the tests. A fitness value of 1.0 shows that the repaired program satisfies all tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "349"
        ]
      },
      "outputs": [],
      "source": [
        "fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "350"
        ]
      },
      "outputs": [],
      "source": [
        "# docassert\n",
        "assert fitness >= 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "351"
        ]
      },
      "source": [
        "Hence, the above program indeed is a perfect repair in the sense that all previously failing tests now pass \u2013 our repair was successful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "352"
        ]
      },
      "source": [
        "Here are the classes defined in this chapter. A `Repairer` repairs a program, using a `StatementMutator` and a `CrossoverOperator` to evolve a population of candidates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "353"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "from ClassDiagram import display_class_hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "354"
        ]
      },
      "outputs": [],
      "source": [
        "# ignore\n",
        "display_class_hierarchy([Repairer, ConditionMutator, CrossoverOperator],\n",
        "                        abstract_classes=[\n",
        "                            NodeVisitor,\n",
        "                            NodeTransformer\n",
        "                        ],\n",
        "                        public_methods=[\n",
        "                            Repairer.__init__,\n",
        "                            Repairer.repair,\n",
        "                            StatementMutator.__init__,\n",
        "                            StatementMutator.mutate,\n",
        "                            ConditionMutator.__init__,\n",
        "                            CrossoverOperator.__init__,\n",
        "                            CrossoverOperator.crossover,\n",
        "                        ],\n",
        "                        project='debuggingbook')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": true,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "355"
        ]
      },
      "source": [
        "## Lessons Learned\n",
        "\n",
        "* Automated repair based on genetic optimization uses five ingredients:\n",
        "    1. A _test suite_ to determine passing and failing tests\n",
        "    2. _Defect localization_ (typically obtained from [statistical debugging](StatisticalDebugger.ipynb) with the test suite) to determine potential locations to be fixed\n",
        "    3. _Random code mutations_ and _crossover operations_ to create and evolve a population of inputs\n",
        "    4. A _fitness function_ and a _selection strategy_ to determine the part of the population that should be evolved further\n",
        "    5. A _reducer_ such as [delta debugging](DeltaDebugger.ipynb) to simplify the final candidate with the highest fitness.\n",
        "* The result of automated repair is a _fix candidate_ with the highest fitness for the given tests.\n",
        "* A _fix candidate_ is not guaranteed to be correct or optimal, but gives important hints on how to fix the program.\n",
        "* All the above ingredients offer plenty of settings and alternatives to experiment with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "356"
        ]
      },
      "source": [
        "## Background\n",
        "\n",
        "The seminal work in automated repair is [GenProg](https://squareslab.github.io/genprog-code/) \\cite{LeGoues2012}, which heavily inspired our `Repairer` implementation. Major differences between GenProg and `Repairer` include:\n",
        "\n",
        "* GenProg includes its own defect localization (which is also dynamically updated), whereas `Repairer` builds on earlier statistical debugging.\n",
        "* GenProg can apply multiple mutations on programs (or none at all), whereas `Repairer` applies exactly one mutation.\n",
        "* The `StatementMutator` used by `Repairer` includes various special cases for program structures (`if`, `for`, `while`...), whereas GenProg operates on statements only.\n",
        "* GenProg has been tested on large production programs.\n",
        "\n",
        "While GenProg is _the_ seminal work in the area (and arguably the most important software engineering research contribution of the 2010s), there have been a number of important extensions of automated repair. These include:\n",
        "\n",
        "* *AutoFix* \\cite{Pei2014} leverages _program contracts_ (pre- and postconditions) to generate tests and assertions automatically. Not only do such [assertions](Assertions.ipynb) help in fault localization, they also allow for much better validation of fix candidates.\n",
        "* *SemFix* \\cite{Nguyen2013} and its successor *[Angelix](http://angelix.io)* \\cite{Mechtaev2016}\n",
        "introduce automated program repair based on _symbolic analysis_ rather than genetic optimization. This allows leveraging program semantics, which GenProg does not consider.\n",
        "\n",
        "To learn more about automated program repair, see [program-repair.org](http://program-repair.org), the community page dedicated to research in program repair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": true,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "357"
        ]
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "tags": [
          "358"
        ]
      },
      "source": [
        "### Exercise 1: Automated Repair Parameters\n",
        "\n",
        "Automated Repair is influenced by numerous design choices \u2013 the size of the population, the number of iterations, the genetic optimization strategy, and more. How do changes to these design choices affect its effectiveness? \n",
        "\n",
        "* Consider the constants defined in this chapter (such as `POPULATION_SIZE` or `WEIGHT_PASSING` vs. `WEIGHT_FAILING`). How do changes affect the effectiveness of automated repair?\n",
        "* As an effectiveness metric, consider the number of iterations it takes to produce a fix candidate.\n",
        "* Since genetic optimization is a random algorithm, you need to determine effectiveness averages over a large number of runs (say, 100)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "solution": "hidden",
        "solution2": "hidden",
        "solution2_first": true,
        "solution_first": true,
        "tags": [
          "359"
        ]
      },
      "source": [
        "### Exercise 2: Elitism\n",
        "\n",
        "[_Elitism_](https://en.wikipedia.org/wiki/Genetic_algorithm#Elitism) (also known as _elitist selection_) is a variant of genetic selection in which a small fraction of the fittest candidates of the last population are included unchanged in the offspring.\n",
        "\n",
        "* Implement elitist selection by subclassing the `evolve()` method. Experiment with various fractions (5%, 10%, 25%) of \"elites\" and see how this improves results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "solution": "hidden",
        "solution2": "hidden",
        "solution2_first": true,
        "solution_first": true,
        "tags": [
          "360"
        ]
      },
      "source": [
        "### Exercise 3: Evolving Values\n",
        "\n",
        "Following the steps of `ConditionMutator`, implement a `ValueMutator` class that replaces one constant value by another one found in the source (say, `0` by `1` or `True` by `False`).\n",
        "\n",
        "For validation, consider the following failure in the `square_root()` function from the [chapter on assertions](Assertions.ipynb):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "361"
        ]
      },
      "outputs": [],
      "source": [
        "from Assertions import square_root  # minor dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "362"
        ]
      },
      "outputs": [],
      "source": [
        "with ExpectError():\n",
        "    square_root_of_zero = square_root(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "solution2": "hidden",
        "solution2_first": true,
        "tags": [
          "363"
        ]
      },
      "source": [
        "Can your `ValueMutator` automatically fix this failure?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "solution2": "hidden",
        "tags": [
          "364"
        ]
      },
      "source": [
        "**Solution.** Your solution will be effective if it also includes named constants such as `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "solution2": "hidden",
        "tags": [
          "365"
        ]
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "solution2": "hidden",
        "tags": [
          "366"
        ]
      },
      "outputs": [],
      "source": [
        "def square_root_fixed(x):  # type: ignore\n",
        "    assert x >= 0  # precondition\n",
        "\n",
        "    approx = 0  # <-- FIX: Change `None` to 0\n",
        "    guess = x / 2\n",
        "    while approx != guess:\n",
        "        approx = guess\n",
        "        guess = (approx + x / approx) / 2\n",
        "\n",
        "    assert math.isclose(approx * approx, x)\n",
        "    return approx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        },
        "solution2": "hidden",
        "tags": [
          "367"
        ]
      },
      "outputs": [],
      "source": [
        "square_root_fixed(0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "solution": "hidden",
        "solution2": "hidden",
        "solution2_first": true,
        "solution_first": true,
        "tags": [
          "368"
        ]
      },
      "source": [
        "### Exercise 4: Evolving Variable Names\n",
        "\n",
        "Following the steps of `ConditionMutator`, implement a `IdentifierMutator` class that replaces one identifier by another one found in the source (say, `y` by `x`). Does it help to fix the `middle()` error?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "solution": "hidden",
        "solution2": "hidden",
        "solution2_first": true,
        "solution_first": true,
        "tags": [
          "369"
        ]
      },
      "source": [
        "### Exercise 5: Parallel Repair\n",
        "\n",
        "Automatic Repair is a technique that is embarrassingly parallel \u2013 all tests for one candidate can all be run in parallel, and all tests for _all_ candidates can also be run in parallel. Set up an infrastructure for running concurrent tests using Pythons [asyncio](https://docs.python.org/3/library/asyncio.html) library."
      ]
    }
  ],
  "metadata": {
    "ipub": {
      "bibliography": "fuzzingbook.bib",
      "toc": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "toc-autonumbering": false,
    "vscode": {
      "interpreter": {
        "hash": "4185989cf89c47c310c2629adcadd634093b57a2c49dffb5ae8d0d14fa302f2b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}